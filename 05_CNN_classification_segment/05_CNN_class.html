<!DOCTYPE html>
<html lang="en"><head>
<script src="05_CNN_class_files/libs/clipboard/clipboard.min.js"></script>
<script src="05_CNN_class_files/libs/quarto-html/tabby.min.js"></script>
<script src="05_CNN_class_files/libs/quarto-html/popper.min.js"></script>
<script src="05_CNN_class_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="05_CNN_class_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="05_CNN_class_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="05_CNN_class_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="05_CNN_class_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.361">

  <title>cnn_class</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="05_CNN_class_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="05_CNN_class_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #97947a;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #97947a;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2; background-color: #2b2b2b; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #dcc6e0; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #ffd700; } /* Attribute */
    code span.bn { color: #dcc6e0; } /* BaseN */
    code span.bu { color: #f5ab35; } /* BuiltIn */
    code span.cf { color: #ffa07a; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffa07a; } /* Constant */
    code span.co { color: #d4d0ab; } /* Comment */
    code span.cv { color: #d4d0ab; font-style: italic; } /* CommentVar */
    code span.do { color: #d4d0ab; font-style: italic; } /* Documentation */
    code span.dt { color: #dcc6e0; } /* DataType */
    code span.dv { color: #dcc6e0; } /* DecVal */
    code span.er { color: #dcc6e0; } /* Error */
    code span.ex { color: #ffd700; } /* Extension */
    code span.fl { color: #f5ab35; } /* Float */
    code span.fu { color: #ffd700; } /* Function */
    code span.im { color: #f8f8f2; } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; } /* Keyword */
    code span.op { color: #00e0e0; } /* Operator */
    code span.ot { color: #ffa07a; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.sc { color: #00e0e0; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #f5ab35; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #d4d0ab; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="05_CNN_class_files/libs/revealjs/dist/theme/quarto.css">
  <link href="05_CNN_class_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="05_CNN_class_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="05_CNN_class_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="05_CNN_class_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="twitter:title" content="Outrageously efficient exploratory data analysis with Apache Arrow and dplyr">
  <meta name="twitter:description" content="A 10 minute lightning talk on all things arrow + dplyr">
  <meta name="twitter:url" content="https://jthomasmock.github.io/arrow-dplyr/#/">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/jthomasmock/arrow-dplyr/master/index-img.png">
  <meta name="twitter:image:alt" content="The title slide of the presentation, with the arrow and dplyr hex logos">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:creator" content="@thomas_mock">
  <meta name="twitter:site" content="@thomas_mock">
  <meta property="og:title" content="Outrageously efficient exploratory data analysis with Apache Arrow and dplyr">
  <meta property="og:description" content="A 10 minute lightning talk on all things arrow + dplyr">
  <meta property="og:url" content="https://jthomasmock.github.io/arrow-dplyr/#/">
  <meta property="og:image" content="https://raw.githubusercontent.com/jthomasmock/arrow-dplyr/master/index-img.png">
  <meta property="og:image:alt" content="The title slide of the presentation, with the arrow and dplyr hex logos">
  <meta property="og:type" content="website">
  <meta property="og:locale" content="en_US">
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">


<section id="convolutional-neural-networks-classification" class="slide level2">
<h2>Convolutional Neural Networks &amp; Classification</h2>
<br>
<h2>
Data Science in Electron Microscopy
</h2>
<hr>
<h3>
Philipp Pelz
</h3>
<h3>
2024
</h3>
<p><br></p>
<h3>
&nbsp; <a href="https://github.com/ECLIPSE-Lab/SS24_DataScienceForEM">https://github.com/ECLIPSE-Lab/SS24_DataScienceForEM</a>
</h3>
</section>
<section id="regression" class="slide level2">
<h2>Regression</h2>
<ul>
<li>Used to answer <em>how much?</em> or <em>how many?</em> questions.
<ul>
<li>Predicting house prices.</li>
<li>Estimating baseball team wins.</li>
<li>Forecasting patient hospital stay duration.</li>
</ul></li>
<li>Important distinctions within regression:
<ul>
<li>House price: Non-negative, often relative to baseline price.
<ul>
<li>Regress on logarithm of price.</li>
</ul></li>
<li>Hospital stay duration: Discrete, nonnegative.
<ul>
<li>Least mean squares may not be ideal.</li>
<li>Specialized subfield: <em>survival modeling</em>.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="key-points" class="slide level2">
<h2>Key Points</h2>
<ul>
<li>Estimation involves more than minimizing squared errors.</li>
<li>Supervised learning encompasses more than regression.</li>
</ul>
<h3 id="focus-of-this-section">Focus of this Section</h3>
<ul>
<li>Classification problems.
<ul>
<li>Shift focus from <em>how much?</em> to <em>which category?</em> questions.</li>
</ul></li>
</ul>
<h3 id="classification-examples">Classification Examples</h3>
<ul>
<li>Does this email belong in the spam folder or the inbox?</li>
<li>Is this customer more likely to sign up or not to sign up for a subscription service?</li>
<li>Does this image depict a donkey, a dog, a cat, or a rooster?</li>
<li>Which movie is Aston most likely to watch next?</li>
<li>Which section of the book are you going to read next?</li>
</ul>
</section>
<section id="understanding-classification" class="slide level2">
<h2>Understanding Classification</h2>
<ul>
<li>Colloquially, <em>classification</em> refers to:
<ol type="1">
<li>Hard assignments of examples to categories (classes).</li>
<li>Soft assignments, assessing the probability of each category.</li>
</ol></li>
<li>Distinction between hard and soft assignments often blurred:
<ul>
<li>Models making soft assignments used even for hard assignment tasks.</li>
</ul></li>
</ul>
<h3 id="multi-label-classification">Multi-Label Classification</h3>
<ul>
<li>Some cases involve more than one true label:
<ul>
<li>Example: A news article covering entertainment, business, and space flight, but not medicine or sports.</li>
</ul></li>
<li>Known as <a href="#/understanding-classification">multi-label classification</a>(https://en.wikipedia.org/wiki/</li>
</ul>
</section>
<section id="simple-image-classification-problem" class="slide level2">
<h2>Simple Image Classification Problem</h2>
<h3 id="problem-setup">Problem Setup</h3>
<ul>
<li><strong>Input</strong>: <span class="math inline">\(2 \times 2\)</span> grayscale image.
<ul>
<li>Each pixel value represented by a scalar.</li>
<li>Four features: <span class="math inline">\(x_1, x_2, x_3, x_4\)</span>.</li>
</ul></li>
<li><strong>Categories</strong>: “cat”, “chicken”, “dog”.</li>
</ul>
<h3 id="label-representation">Label Representation</h3>
</section>
<section class="slide level2">

<h4 id="natural-impulse">Natural Impulse</h4>
<ul>
<li>Use <span class="math inline">\(y \in \{1, 2, 3\}\)</span> for <span class="math inline">\(\{\text{dog}, \text{cat}, \text{chicken}\}\)</span> respectively.
<ul>
<li>Efficient for storage.</li>
<li>Suitable for ordinal data with natural ordering, e.g., age categories.</li>
</ul></li>
</ul>
<h4 id="ordinal-regression">Ordinal Regression</h4>
<ul>
<li>Useful for naturally ordered categories.</li>
<li>Resources:
<ul>
<li>Overview of ranking loss functions: :citet:<code>Moon.Smola.Chang.ea.2010</code>.</li>
<li>Bayesian approach for multi-modal responses: :citet:<code>Beutel.Murray.Faloutsos.ea.2014</code>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="one-hot-encoding">One-Hot Encoding</h3>
<ul>
<li>Suitable for unordered categorical data.</li>
<li>Vector with components for each category.</li>
<li>Example:
<ul>
<li>“cat” → <span class="math inline">\((1, 0, 0)\)</span></li>
<li>“chicken” → <span class="math inline">\((0, 1, 0)\)</span></li>
<li>“dog” → <span class="math inline">\((0, 0, 1)\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[y \in \{(1, 0, 0), (0, 1, 0), (0, 0, 1)\}.\]</span></p>
</section>
<section id="linear-model" class="slide level2">
<h2>Linear Model</h2>
<h3 id="estimating-conditional-probabilities">Estimating Conditional Probabilities</h3>
<ul>
<li><strong>Objective</strong>: Estimate conditional probabilities for all classes.</li>
<li><strong>Model Requirement</strong>: Multiple outputs (one per class).</li>
</ul>
<h3 id="affine-functions-for-classification">Affine Functions for Classification</h3>
<ul>
<li>Need as many affine functions as output categories.</li>
<li>For symmetry, use redundant parametrization:
<ul>
<li>Last category derived from others.</li>
</ul></li>
<li><strong>Case Example</strong>:
<ul>
<li>4 features, 3 output categories.</li>
<li>12 scalars for weights (<span class="math inline">\(w_{ij}\)</span>) and 3 scalars for biases (<span class="math inline">\(b_i\)</span>).</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="model-equations">Model Equations</h3>
<p><span class="math display">\[
\begin{aligned}
o_1 &amp;= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\
o_2 &amp;= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\
o_3 &amp;= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
\end{aligned}
\]</span></p>
</section>
<section class="slide level2">

<h3 id="neural-network-diagram">Neural Network Diagram</h3>
<ul>
<li><strong>Diagram</strong>: See :numref:<code>fig_softmaxreg</code>.</li>
<li><strong>Structure</strong>:
<ul>
<li>Single-layer neural network (similar to linear regression).</li>
<li>Each output (<span class="math inline">\(o_1, o_2, o_3\)</span>) depends on all inputs ($x_1, x_2, <span class="math inline">\(x_3\)</span>, <span class="math inline">\(x_4\)</span>).</li>
<li>Output layer described as a <em>fully connected layer</em>.</li>
</ul></li>
</ul>
<p><img data-src="../img/softmaxreg.svg" style="width:40.0%" alt="Softmax regression is a single-layer neural network."> <code>fig_softmaxreg</code></p>
</section>
<section class="slide level2">

<h3 id="concise-notation-with-vectors-and-matrices">Concise Notation with Vectors and Matrices</h3>
<ul>
<li>Use vectors and matrices for concise notation:
<ul>
<li><span class="math inline">\(\mathbf{o} = \mathbf{W} \mathbf{x} + \mathbf{b}\)</span></li>
<li>Suited for mathematics and code implementation.</li>
</ul></li>
<li><strong>Weights and Biases</strong>:
<ul>
<li>Weights gathered into a <span class="math inline">\(3 \times 4\)</span> matrix.</li>
<li>Biases <span class="math inline">\(\mathbf{b} \in \mathbb{R}^3\)</span> in a vector.</li>
</ul></li>
</ul>
</section>
<section id="the-softmax" class="slide level2">
<h2>The Softmax</h2>
<p>:label:<code>subsec_softmax_operation</code></p>
<h3 id="limitations-of-vector-valued-regression">Limitations of Vector-Valued Regression</h3>
<ul>
<li>Directly minimizing the difference between <span class="math inline">\(\mathbf{o}\)</span> and labels <span class="math inline">\(\mathbf{y}\)</span> has drawbacks:
<ul>
<li>No guarantee that outputs <span class="math inline">\(o_i\)</span> sum to 1 (expected for probabilities).</li>
<li>Outputs <span class="math inline">\(o_i\)</span> might be negative or exceed 1 even if they sum to 1.</li>
</ul></li>
<li>These issues complicate the estimation problem and make solutions brittle to outliers.</li>
</ul>
<h3 id="example-problem">Example Problem</h3>
<ul>
<li>Positive linear dependency between number of bedrooms and likelihood of buying a house:
<ul>
<li>Probability might exceed 1 for a mansion.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="solution-squish-the-outputs">Solution: Squish the Outputs</h3>
<h4 id="probit-model">Probit Model</h4>
<ul>
<li>Assume outputs <span class="math inline">\(\mathbf{o}\)</span> are corrupted versions of <span class="math inline">\(\mathbf{y}\)</span>:
<ul>
<li><span class="math inline">\(\mathbf{y} = \mathbf{o} + \mathbf{\epsilon}\)</span>, with <span class="math inline">\(\epsilon_i \sim \mathcal{N}(0, \sigma^2)\)</span>.</li>
<li>Known as the <a href="https://en.wikipedia.org/wiki/Probit_model">probit model</a>, introduced by :citet:<code>Fechner.1860</code>.</li>
<li>Less effective and harder to optimize compared to softmax.</li>
</ul></li>
</ul>
<h4 id="softmax-function">Softmax Function</h4>
<ul>
<li>Use an exponential function: <span class="math inline">\(P(y = i) \propto \exp o_i\)</span>.
<ul>
<li>Ensures nonnegative probabilities.</li>
<li>Monotonic relationship: Conditional class probability increases with <span class="math inline">\(o_i\)</span>.</li>
</ul></li>
<li>Normalize to ensure probabilities sum to 1:
<ul>
<li>Divide each exponential value by their sum.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="softmax-function-1">Softmax Function</h3>
<p><span class="math display">\[\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o}) \quad \text{where}\quad \hat{y}_i = \frac{\exp(o_i)}{\sum_j \exp(o_j)}.\]</span> :eqlabel:<code>eq_softmax_y_and_o</code></p>
<ul>
<li>The largest coordinate of <span class="math inline">\(\mathbf{o}\)</span> corresponds to the most likely class according to <span class="math inline">\(\hat{\mathbf{y}}\)</span>.</li>
<li>Softmax preserves the ordering among its arguments:
<ul>
<li>To determine the highest probability class, compute:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\operatorname*{argmax}_j \hat y_j = \operatorname*{argmax}_j o_j.
\]</span></p>
</section>
<section id="vectorization" class="slide level2">
<h2>Vectorization</h2>
<h3 id="computational-efficiency-with-vectorization">Computational Efficiency with Vectorization</h3>
<ul>
<li><strong>Minibatch</strong>: <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times d}\)</span>
<ul>
<li><span class="math inline">\(n\)</span> examples, each with <span class="math inline">\(d\)</span> inputs.</li>
</ul></li>
<li><strong>Output Categories</strong>: <span class="math inline">\(q\)</span> categories
<ul>
<li>Weights: <span class="math inline">\(\mathbf{W} \in \mathbb{R}^{d \times q}\)</span></li>
<li>Bias: <span class="math inline">\(\mathbf{b} \in \mathbb{R}^{1 \times q}\)</span></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="vectorized-equations">Vectorized Equations</h3>
<p><span class="math display">\[
\begin{aligned}
\mathbf{O} &amp;= \mathbf{X} \mathbf{W} + \mathbf{b}, \\
\hat{\mathbf{Y}} &amp; = \mathrm{softmax}(\mathbf{O}).
\end{aligned}
\]</span> <code>eq_minibatch_softmax_reg</code></p>
<ul>
<li><strong>Efficiency</strong>: Converts the dominant operation to matrix-matrix product <span class="math inline">\(\mathbf{X} \mathbf{W}\)</span>.</li>
<li><strong>Rowwise Softmax</strong>:
<ul>
<li>Exponentiate entries in each row of <span class="math inline">\(\mathbf{O}\)</span>.</li>
<li>Normalize by the sum for each row.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="numerical-stability">Numerical Stability</h3>
<ul>
<li><strong>Care Needed</strong>: Avoid overflow/underflow with large numbers.</li>
<li><strong>Deep Learning Frameworks</strong>: Handle these issues automatically.</li>
</ul>
</section>
<section id="loss-function" class="slide level2">
<h2>Loss Function</h2>
<h3 id="mapping-features-to-probabilities">Mapping Features to Probabilities</h3>
<ul>
<li>Goal: Optimize the accuracy of mapping from features <span class="math inline">\(\mathbf{x}\)</span> to probabilities <span class="math inline">\(\mathbf{\hat{y}}\)</span>.</li>
<li>Method: Maximum likelihood estimation.
<ul>
<li>Same concept as used for probabilistic justification of mean squared error loss in :numref:<code>subsec_normal_distribution_and_squared_loss</code>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="log-likelihood">Log-Likelihood</h3>
<ul>
<li><strong>Softmax Output</strong>: Vector <span class="math inline">\(\hat{\mathbf{y}}\)</span> interpreted as estimated conditional probabilities:
<ul>
<li>Example: <span class="math inline">\(\hat{y}_1 = P(y=\text{cat} \mid \mathbf{x})\)</span>.</li>
</ul></li>
<li><strong>Dataset Representation</strong>:
<ul>
<li>Features: <span class="math inline">\(\mathbf{X}\)</span></li>
<li>Labels: <span class="math inline">\(\mathbf{Y}\)</span> (one-hot encoded).</li>
</ul></li>
<li><strong>Probability Comparison</strong>:
<ul>
<li>Compare estimated probabilities with actual classes:</li>
</ul></li>
</ul>
<p><span class="math display">\[
P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}).
\]</span></p>
<ul>
<li><strong>Factorization</strong>: Assumes each label is drawn independently</li>
</ul>
</section>
<section class="slide level2">

<h3 id="negative-log-likelihood">Negative Log-Likelihood</h3>
<p><span class="math display">\[
-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}),
\]</span></p>
<ul>
<li><strong>Loss Function</strong>: For any pair of label <span class="math inline">\(\mathbf{y}\)</span> and model prediction <span class="math inline">\(\hat{\mathbf{y}}\)</span> over <span class="math inline">\(q\)</span> classes:</li>
</ul>
<p><span class="math display">\[
l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j.
\]</span> :eqlabel:<code>eq_l_cross_entropy</code></p>
</section>
<section class="slide level2">

<h3 id="cross-entropy-loss">Cross-Entropy Loss</h3>
<ul>
<li><strong>Definition</strong>: Loss function in :eqref:<code>eq_l_cross_entropy</code> is called <em>cross-entropy loss</em>.</li>
<li><strong>One-Hot Vector</strong>: <span class="math inline">\(\mathbf{y}\)</span> is a one-hot vector of length <span class="math inline">\(q\)</span>.
<ul>
<li>Sum over all coordinates <span class="math inline">\(j\)</span> vanishes for all but one term.</li>
</ul></li>
</ul>
<h3 id="properties-of-cross-entropy-loss">Properties of Cross-Entropy Loss</h3>
<ul>
<li><strong>Bounded Below by 0</strong>: Loss <span class="math inline">\(l(\mathbf{y}, \hat{\mathbf{y}})\)</span> is bounded from below by <span class="math inline">\(0\)</span> when <span class="math inline">\(\hat{y}\)</span> is a probability vector.
<ul>
<li>No single entry larger than <span class="math inline">\(1\)</span>, negative logarithm cannot be lower than <span class="math inline">\(0\)</span>.</li>
<li><span class="math inline">\(l(\mathbf{y}, \hat{\mathbf{y}}) = 0\)</span> only if the actual label is predicted with certainty.</li>
<li>Predicting with certainty requires input <span class="math inline">\(o_i\)</span> to go to infinity (or others to negative infinity).</li>
</ul></li>
<li><strong>Infinite Loss</strong>: Assigning a probability of <span class="math inline">\(0\)</span> incurs infinite loss (<span class="math inline">\(-\log 0 = \infty\)</span>).
<ul>
<li>High confidence errors result in infinite loss.</li>
</ul></li>
</ul>
</section>
<section id="softmax-and-cross-entropy-loss" class="slide level2">
<h2>Softmax and Cross-Entropy Loss</h2>
<p>:label:<code>subsec_softmax_and_derivatives</code></p>
<h3 id="calculation-of-softmax-and-cross-entropy-loss">Calculation of Softmax and Cross-Entropy Loss</h3>
<ul>
<li><strong>Combining Equations</strong>:
<ul>
<li>Plugging :eqref:<code>eq_softmax_y_and_o</code> into the definition of the loss in :eqref:<code>eq_l_cross_entropy</code>:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
l(\mathbf{y}, \hat{\mathbf{y}}) &amp;=  - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\
&amp;= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j \\
&amp;= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j.
\end{aligned}
\]</span></p>
</section>
<section class="slide level2">

<h3 id="derivative-with-respect-to-logit-o_j">Derivative with Respect to Logit <span class="math inline">\(o_j\)</span></h3>
<p><span class="math display">\[
\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \mathrm{softmax}(\mathbf{o})_j - y_j.
\]</span></p>
<ul>
<li><strong>Interpretation</strong>:
<ul>
<li>Derivative is the difference between model probability (softmax) and actual label (one-hot vector).</li>
<li>Similar to regression where gradient was the difference between observation <span class="math inline">\(y\)</span> and estimate <span class="math inline">\(\hat{y}\)</span>.</li>
<li>In exponential family models, gradients of log-likelihood are given by this term, making gradient computation easy.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="distribution-over-outcomes">Distribution Over Outcomes</h3>
<ul>
<li><strong>General Case</strong>:
<ul>
<li>Observe entire distribution over outcomes.</li>
<li>Label <span class="math inline">\(\mathbf{y}\)</span> as a probability vector (e.g., <span class="math inline">\((0.1, 0.2, 0.7)\)</span>) instead of binary vector.</li>
</ul></li>
<li><strong>Mathematical Consistency</strong>:
<ul>
<li>The same loss function <span class="math inline">\(l\)</span> in :eqref:<code>eq_l_cross_entropy</code> applies.</li>
<li>Represents expected value of the loss for a distribution over labels.</li>
</ul></li>
</ul>
<h3 id="cross-entropy-loss-1">Cross-Entropy Loss</h3>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Measures the number of bits to encode actual observation <span class="math inline">\(\mathbf{y}\)</span> relative to prediction <span class="math inline">\(\hat{\mathbf{y}}\)</span>.</li>
<li>Commonly used for classification problems.</li>
</ul></li>
<li><strong>Information Theory</strong>:
<ul>
<li>Basic explanation relates to encoding efficiency.</li>
<li>For detailed information, refer to:
<ul>
<li>:citet:<code>Cover.Thomas.1999</code></li>
<li>:citet:<code>mackay2003information</code></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="information-theory-basics" class="slide level2">
<h2>Information Theory Basics</h2>
<p>:label:<code>subsec_info_theory_basics</code></p>
<p>Many deep learning papers use intuition and terms from information theory. To make sense of them, we need some common language. This is a survival guide. <em>Information theory</em> deals with the problem of encoding, decoding, transmitting, and manipulating information (also known as data).</p>
<h3 id="entropy">Entropy</h3>
<ul>
<li><strong>Central Idea</strong>: Quantify the amount of information contained in data, placing a limit on data compression.</li>
<li><strong>Definition</strong>: For a distribution <span class="math inline">\(P\)</span>, its <em>entropy</em> is:</li>
</ul>
<p><span class="math display">\[
H[P] = \sum_j - P(j) \log P(j).
\]</span> <code>eq_softmax_reg_entropy</code></p>
</section>
<section class="slide level2">

<ul>
<li><strong>Fundamental Theorem</strong>: To encode data drawn randomly from distribution <span class="math inline">\(P\)</span>, we need at least <span class="math inline">\(H[P]\)</span> “nats” to encode it :cite:<code>Shannon.1948</code>.
<ul>
<li><strong>Nat</strong>: Equivalent of a bit but using base <span class="math inline">\(e\)</span> instead of base 2.</li>
<li>1 nat ≈ 1.44 bits.</li>
</ul></li>
</ul>
<h3 id="surprisal">Surprisal</h3>
<ul>
<li><strong>Compression and Prediction</strong>: Easy-to-predict data is easy to compress.
<ul>
<li>Example: A data stream where every token is the same is easy to predict and compress.</li>
</ul></li>
<li><strong>Surprise</strong>: Greater when an event has a lower assigned probability.
<ul>
<li>Claude Shannon quantified <em>surprisal</em> at observing an event <span class="math inline">\(j\)</span> with probability <span class="math inline">\(P(j)\)</span> as <span class="math inline">\(\log \frac{1}{P(j)} = -\log P(j)\)</span>.</li>
</ul></li>
<li><strong>Expected Surprisal</strong>: Entropy defined in :eqref:<code>eq_softmax_reg_entropy</code> is the <em>expected surprisal</em> when probabilities match the data-generating process.</li>
</ul>
</section>
<section id="cross-entropy-revisited" class="slide level2">
<h2>Cross-Entropy Revisited</h2>
<h3 id="definition-and-interpretation">Definition and Interpretation</h3>
<ul>
<li><strong>Entropy</strong>: The level of surprise experienced by someone who knows the true probability.</li>
<li><strong>Cross-Entropy</strong>: The expected surprisal of an observer with subjective probabilities <span class="math inline">\(Q\)</span> upon seeing data generated according to probabilities <span class="math inline">\(P\)</span>.
<ul>
<li>Denoted as <span class="math inline">\(H(P, Q)\)</span>.</li>
<li>Formula: <span class="math inline">\(H(P, Q) \stackrel{\mathrm{def}}{=} \sum_j - P(j) \log Q(j)\)</span>.</li>
<li>Lowest cross-entropy achieved when <span class="math inline">\(P = Q\)</span>: <span class="math inline">\(H(P, P) = H(P)\)</span>.</li>
</ul></li>
</ul>
<h3 id="cross-entropy-in-classification">Cross-Entropy in Classification</h3>
<ul>
<li>Two perspectives on cross-entropy classification objective:
<ol type="1">
<li>Maximizing the likelihood of observed data.</li>
<li>Minimizing surprisal (and thus the number of bits) required to communicate the labels.</li>
</ol></li>
</ul>
</section>
<section id="summary-and-discussion" class="slide level2">
<h2>Summary and Discussion</h2>
<h3 id="key-points-1">Key Points</h3>
<ul>
<li>Introduced the first nontrivial loss function for optimizing over <em>discrete</em> output spaces.</li>
<li>Used a probabilistic approach, treating discrete categories as instances of draws from a probability distribution.</li>
<li>Encountered the softmax activation function, transforming neural network outputs into valid discrete probability distributions.</li>
<li>Derivative of cross-entropy loss combined with softmax is similar to the derivative of squared error (difference between expected behavior and prediction).</li>
<li>Briefly touched on connections to statistical physics and information theory.</li>
</ul>
</section>
<section id="exercises" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>We can explore the connection between exponential families and the softmax in some more depth.
<ol type="1">
<li>Compute the second derivative of the cross-entropy loss <span class="math inline">\(l(\mathbf{y},\hat{\mathbf{y}})\)</span> for the softmax.</li>
<li>Compute the variance of the distribution given by <span class="math inline">\(\mathrm{softmax}(\mathbf{o})\)</span> and show that it matches the second derivative computed above.</li>
</ol></li>
<li>Assume that we have three classes which occur with equal probability, i.e., the probability vector is <span class="math inline">\((\frac{1}{3}, \frac{1}{3}, \frac{1}{3})\)</span>.
<ol type="1">
<li>What is the problem if we try to design a binary code for it?</li>
<li>Can you design a better code? Hint: what happens if we try to encode two independent observations? What if we encode <span class="math inline">\(n\)</span> observations jointly?</li>
</ol></li>
<li>When encoding signals transmitted over a physical wire, engineers do not always use binary codes. For instance, <a href="https://en.wikipedia.org/wiki/Ternary_signal">PAM-3</a> uses three signal levels <span class="math inline">\(\{-1, 0, 1\}\)</span> as opposed to two levels <span class="math inline">\(\{0, 1\}\)</span>. How many ternary units do you need to transmit an integer in the range <span class="math inline">\(\{0, \ldots, 7\}\)</span>? Why might this be a better idea in terms of electronics?</li>
</ol>
</section>
<section class="slide level2">

<ol type="1">
<li>The <a href="https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model">Bradley-Terry model</a> uses a logistic model to capture preferences. For a user to choose between apples and oranges one assumes scores <span class="math inline">\(o_{\mathrm{apple}}\)</span> and <span class="math inline">\(o_{\mathrm{orange}}\)</span>. Our requirements are that larger scores should lead to a higher likelihood in choosing the associated item and that the item with the largest score is the most likely one to be chosen :cite:<code>Bradley.Terry.1952</code>.
<ol type="1">
<li>Prove that the softmax satisfies this requirement.</li>
<li>What happens if you want to allow for a default option of choosing neither apples nor oranges? Hint: now the user has 3 choices.</li>
</ol></li>
<li>Softmax derives its name from the following mapping: <span class="math inline">\(\mathrm{RealSoftMax}(a, b) = \log (\exp(a) + \exp(b))\)</span>.
<ol type="1">
<li>Prove that <span class="math inline">\(\mathrm{RealSoftMax}(a, b) &gt; \mathrm{max}(a, b)\)</span>.</li>
<li>How small can you make the difference between both functions? Hint: without loss of generality you can set <span class="math inline">\(b = 0\)</span> and <span class="math inline">\(a \geq b\)</span>.</li>
<li>Prove that this holds for <span class="math inline">\(\lambda^{-1} \mathrm{RealSoftMax}(\lambda a, \lambda b)\)</span>, provided that <span class="math inline">\(\lambda &gt; 0\)</span>.</li>
<li>Show that for <span class="math inline">\(\lambda \to \infty\)</span> we have <span class="math inline">\(\lambda^{-1} \mathrm{RealSoftMax}(\lambda a, \lambda b) \to \mathrm{max}(a, b)\)</span>.</li>
<li>What does the soft-min look like?</li>
<li>Extend this to more than two numbers.</li>
</ol></li>
</ol>
</section>
<section class="slide level2">

<ol type="1">
<li>The function <span class="math inline">\(g(\mathbf{x}) \stackrel{\mathrm{def}}{=} \log \sum_i \exp x_i\)</span> is sometimes also referred to as the <a href="https://en.wikipedia.org/wiki/Partition_function_(mathematics)">log-partition function</a>.
<ol type="1">
<li>Prove that the function is convex. Hint: to do so, use the fact that the first derivative amounts to the probabilities from the softmax function and show that the second derivative is the variance.</li>
<li>Show that <span class="math inline">\(g\)</span> is translation invariant, i.e., <span class="math inline">\(g(\mathbf{x} + b) = g(\mathbf{x})\)</span>.</li>
<li>What happens if some of the coordinates <span class="math inline">\(x_i\)</span> are very large? What happens if they’re all very small?</li>
<li>Show that if we choose <span class="math inline">\(b = \mathrm{max}_i x_i\)</span> we end up with a numerically stable implementation.</li>
</ol></li>
<li>Assume that we have some probability distribution <span class="math inline">\(P\)</span>. Suppose we pick another distribution <span class="math inline">\(Q\)</span> with <span class="math inline">\(Q(i) \propto P(i)^\alpha\)</span> for <span class="math inline">\(\alpha &gt; 0\)</span>.
<ol type="1">
<li>Which choice of <span class="math inline">\(\alpha\)</span> corresponds to doubling the temperature? Which choice corresponds to halving it?</li>
<li>What happens if we let the temperature converge to <span class="math inline">\(0\)</span>?</li>
<li>What happens if we let the temperature converge to <span class="math inline">\(\infty\)</span>?</li>
</ol></li>
</ol>
</section>
<section id="the-image-classification-dataset" class="slide level2">
<h2>The Image Classification Dataset</h2>
<h3 id="mnist-dataset">MNIST Dataset</h3>
<ul>
<li><strong>Overview</strong>: Widely used for image classification of handwritten digits.
<ul>
<li><strong>Reference</strong>: <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST dataset</a> :cite:<code>LeCun.Bottou.Bengio.ea.1998</code>.</li>
<li><strong>Content</strong>: 60,000 images of <span class="math inline">\(28 \times 28\)</span> pixels resolution (plus a test dataset of 10,000 images).</li>
</ul></li>
<li><strong>Historical Context</strong>:
<ul>
<li>Released in the 1990s, it was a formidable challenge for machine learning algorithms.</li>
<li>Example of state-of-the-art equipment at the time: Sun SPARCStation 5 with 64MB RAM and 5 MFLOPs (AT&amp;T Bell Laboratories, 1995).</li>
</ul></li>
<li><strong>Impact</strong>:
<ul>
<li>High accuracy on digit recognition was crucial for automating letter sorting for the USPS in the 1990s.</li>
<li>Algorithms achieving error rates below 1%:
<ul>
<li>Deep networks like LeNet-5 :cite:<code>LeCun.Jackel.Bottou.ea.1995</code>.</li>
<li>Support vector machines with invariances :cite:<code>Scholkopf.Burges.Vapnik.1996</code>.</li>
<li>Tangent distance classifiers :cite:<code>Simard.LeCun.Denker.ea.1998</code>.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="mnist-as-a-benchmark">MNIST as a Benchmark</h3>
<ul>
<li><strong>Historical Significance</strong>: Served as the reference for comparing machine learning algorithms for over a decade.</li>
<li><strong>Current Relevance</strong>:
<ul>
<li>Simple models achieve classification accuracy over 95%.</li>
<li>Unsuitable for distinguishing between stronger and weaker models due to high levels of accuracy.</li>
<li>Skewed algorithmic development towards methods that excel with clean datasets.</li>
</ul></li>
</ul>
<h3 id="transition-to-fashion-mnist">Transition to Fashion-MNIST</h3>
<ul>
<li><strong>Limitations of MNIST</strong>: More of a sanity check than a benchmark today.</li>
<li><strong>ImageNet</strong>:
<ul>
<li>Poses a more relevant challenge :cite:<code>Deng.Dong.Socher.ea.2009</code>.</li>
<li>Too large for interactive examples and illustrations in this context.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Fashion-MNIST</strong>:
<ul>
<li>Released in 2017 :cite:<code>Xiao.Rasul.Vollgraf.2017</code>.</li>
<li>Contains images of 10 categories of clothing at <span class="math inline">\(28 \times 28\)</span> pixels resolution.</li>
<li>Used as a substitute for MNIST in upcoming sections.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> time</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">from</span> d2l <span class="im">import</span> torch <span class="im">as</span> d2l</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> torch</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> torchvision</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a>d2l.use_svg_display()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="loading-the-dataset">Loading the Dataset</h3>
<p>Since it is such a frequently used dataset, all major frameworks provide preprocessed versions of it. We can [<strong>download and read the Fashion-MNIST dataset into memory using built-in framework utilities.</strong>]</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">class</span> FashionMNIST(d2l.DataModule):  <span class="co">#@save</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span class="co">"""The Fashion-MNIST dataset."""</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, batch_size<span class="op">=</span><span class="dv">64</span>, resize<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>)):</span>
<span id="cb2-4"><a href="#cb2-4"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-5"><a href="#cb2-5"></a>        <span class="va">self</span>.save_hyperparameters()</span>
<span id="cb2-6"><a href="#cb2-6"></a>        trans <span class="op">=</span> transforms.Compose([transforms.Resize(resize),</span>
<span id="cb2-7"><a href="#cb2-7"></a>                                    transforms.ToTensor()])</span>
<span id="cb2-8"><a href="#cb2-8"></a>        <span class="va">self</span>.train <span class="op">=</span> torchvision.datasets.FashionMNIST(</span>
<span id="cb2-9"><a href="#cb2-9"></a>            root<span class="op">=</span><span class="va">self</span>.root, train<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>trans, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-10"><a href="#cb2-10"></a>        <span class="va">self</span>.val <span class="op">=</span> torchvision.datasets.FashionMNIST(</span>
<span id="cb2-11"><a href="#cb2-11"></a>            root<span class="op">=</span><span class="va">self</span>.root, train<span class="op">=</span><span class="va">False</span>, transform<span class="op">=</span>trans, download<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="fashion-mnist-dataset">Fashion-MNIST Dataset</h3>
<ul>
<li><strong>Content</strong>: Images from 10 categories.
<ul>
<li>Each category represented by:
<ul>
<li>6,000 images in the training dataset.</li>
<li>1,000 images in the test dataset.</li>
</ul></li>
</ul></li>
<li><strong>Dataset Sizes</strong>:
<ul>
<li><strong>Training Set</strong>: 60,000 images.</li>
<li><strong>Test Set</strong>: 10,000 images.</li>
</ul></li>
<li><strong>Purpose of Test Dataset</strong>: Used exclusively for evaluating model performance, not for training.</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>data <span class="op">=</span> FashionMNIST(resize<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>))</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="bu">len</span>(data.train), <span class="bu">len</span>(data.val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="image-characteristics">Image Characteristics</h3>
<ul>
<li><strong>Grayscale Images</strong>: Upscaled to <span class="math inline">\(32 \times 32\)</span> pixels resolution.
<ul>
<li>Similar to original MNIST dataset (binary black and white images).</li>
</ul></li>
<li><strong>Modern Image Data</strong>:
<ul>
<li>Typically has 3 channels (red, green, blue).</li>
<li>Hyperspectral images can have over 100 channels (e.g., HyMap sensor has 126 channels).</li>
</ul></li>
<li><strong>Storage Convention</strong>:
<ul>
<li>Images stored as a <span class="math inline">\(c \times h \times w\)</span> tensor.</li>
<li><span class="math inline">\(c\)</span> = number of color channels.</li>
<li><span class="math inline">\(h\)</span> = height.</li>
<li><span class="math inline">\(w\)</span> = width.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>data.train[<span class="dv">0</span>][<span class="dv">0</span>].shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The categories of Fashion-MNIST have human-understandable names. The following convenience method converts between numeric labels and their names.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="at">@d2l.add_to_class</span>(FashionMNIST)  <span class="co">#@save</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="kw">def</span> text_labels(<span class="va">self</span>, indices):</span>
<span id="cb5-3"><a href="#cb5-3"></a>    <span class="co">"""Return text labels."""</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>    labels <span class="op">=</span> [<span class="st">'t-shirt'</span>, <span class="st">'trouser'</span>, <span class="st">'pullover'</span>, <span class="st">'dress'</span>, <span class="st">'coat'</span>,</span>
<span id="cb5-5"><a href="#cb5-5"></a>              <span class="st">'sandal'</span>, <span class="st">'shirt'</span>, <span class="st">'sneaker'</span>, <span class="st">'bag'</span>, <span class="st">'ankle boot'</span>]</span>
<span id="cb5-6"><a href="#cb5-6"></a>    <span class="cf">return</span> [labels[<span class="bu">int</span>(i)] <span class="cf">for</span> i <span class="kw">in</span> indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="reading-a-minibatch">Reading a Minibatch</h3>
<ul>
<li><strong>Data Iterator</strong>: Utilizes built-in data iterator for reading from training and test sets.</li>
<li><strong>Minibatch Size</strong>: At each iteration, a data iterator reads a minibatch of data with size <code>batch_size</code>.</li>
<li><strong>Shuffling</strong>: Randomly shuffle the examples for the training data iterator to ensure better training performance.</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="at">@d2l.add_to_class</span>(FashionMNIST)  <span class="co">#@save</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">def</span> get_dataloader(<span class="va">self</span>, train):</span>
<span id="cb6-3"><a href="#cb6-3"></a>    data <span class="op">=</span> <span class="va">self</span>.train <span class="cf">if</span> train <span class="cf">else</span> <span class="va">self</span>.val</span>
<span id="cb6-4"><a href="#cb6-4"></a>    <span class="cf">return</span> torch.utils.data.DataLoader(data, <span class="va">self</span>.batch_size, shuffle<span class="op">=</span>train,</span>
<span id="cb6-5"><a href="#cb6-5"></a>                                       num_workers<span class="op">=</span><span class="va">self</span>.num_workers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To see how this works, let’s load a minibatch of images by invoking the <code>train_dataloader</code> method. It contains 64 images.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>X, y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(data.train_dataloader()))</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="bu">print</span>(X.shape, X.dtype, y.shape, y.dtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="performance-of-data-loading">Performance of Data Loading</h3>
<ul>
<li><strong>Time to Read Images</strong>: Not extremely fast, but sufficient for our needs.</li>
<li><strong>Context</strong>: Processing images with a deep network takes significantly longer than loading them.</li>
<li><strong>Conclusion</strong>: The data loader’s speed ensures that training a network will not be IO constrained.</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>tic <span class="op">=</span> time.time()</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="cf">for</span> X, y <span class="kw">in</span> data.train_dataloader():</span>
<span id="cb8-3"><a href="#cb8-3"></a>    <span class="cf">continue</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="ss">f'</span><span class="sc">{</span>time<span class="sc">.</span>time() <span class="op">-</span> tic<span class="sc">:.2f}</span><span class="ss"> sec'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="visualization">Visualization</h3>
<ul>
<li><strong>Frequent Use</strong>: We’ll use the Fashion-MNIST dataset frequently.</li>
<li><strong>Convenience Function</strong>: <code>show_images</code> function to visualize images and labels.
<ul>
<li>Implementation details in the appendix.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">def</span> show_images(imgs, num_rows, num_cols, titles<span class="op">=</span><span class="va">None</span>, scale<span class="op">=</span><span class="fl">1.5</span>):  <span class="co">#@save</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>    <span class="co">"""Plot a list of images."""</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>    <span class="cf">raise</span> <span class="pp">NotImplementedError</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="at">@d2l.add_to_class</span>(FashionMNIST)  <span class="co">#@save</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="kw">def</span> visualize(<span class="va">self</span>, batch, nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">8</span>, labels<span class="op">=</span>[]):</span>
<span id="cb10-3"><a href="#cb10-3"></a>    X, y <span class="op">=</span> batch</span>
<span id="cb10-4"><a href="#cb10-4"></a>    <span class="cf">if</span> <span class="kw">not</span> labels:</span>
<span id="cb10-5"><a href="#cb10-5"></a>        labels <span class="op">=</span> <span class="va">self</span>.text_labels(y)</span>
<span id="cb10-6"><a href="#cb10-6"></a>    <span class="cf">if</span> tab.selected(<span class="st">'mxnet'</span>, <span class="st">'pytorch'</span>):</span>
<span id="cb10-7"><a href="#cb10-7"></a>        d2l.show_images(X.squeeze(<span class="dv">1</span>), nrows, ncols, titles<span class="op">=</span>labels)</span>
<span id="cb10-8"><a href="#cb10-8"></a>    <span class="cf">if</span> tab.selected(<span class="st">'tensorflow'</span>):</span>
<span id="cb10-9"><a href="#cb10-9"></a>        d2l.show_images(tf.squeeze(X), nrows, ncols, titles<span class="op">=</span>labels)</span>
<span id="cb10-10"><a href="#cb10-10"></a>    <span class="cf">if</span> tab.selected(<span class="st">'jax'</span>):</span>
<span id="cb10-11"><a href="#cb10-11"></a>        d2l.show_images(jnp.squeeze(X), nrows, ncols, titles<span class="op">=</span>labels)</span>
<span id="cb10-12"><a href="#cb10-12"></a></span>
<span id="cb10-13"><a href="#cb10-13"></a>batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(data.val_dataloader()))</span>
<span id="cb10-14"><a href="#cb10-14"></a>data.visualize(batch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We are now ready to work with the Fashion-MNIST dataset in the sections that follow.</p>
<h3 id="summary">Summary</h3>
<ul>
<li><strong>Dataset</strong>: Fashion-MNIST
<ul>
<li>Apparel classification dataset with images representing 10 categories.</li>
<li>Used to evaluate various network designs from simple linear models to advanced residual networks.</li>
</ul></li>
<li><strong>Image Data</strong>:
<ul>
<li>Read as a tensor of shape (batch size, number of channels, height, width).</li>
<li>Current images are grayscale (visualized with a false color palette for improved visibility).</li>
</ul></li>
<li><strong>Data Iterators</strong>:
<ul>
<li>Essential for efficient performance.</li>
<li>Utilize GPUs for efficient preprocessing tasks like image decompression and video transcoding.</li>
<li>Use well-implemented data iterators to leverage high-performance computing and avoid slowing down the training loop.</li>
</ul></li>
</ul>
<h3 id="exercises-1">Exercises</h3>
<ol type="1">
<li>Does reducing the <code>batch_size</code> (for instance, to 1) affect the reading performance?</li>
<li>The data iterator performance is important. Do you think the current implementation is fast enough? Explore various options to improve it. Use a system profiler to find out where the bottlenecks are.</li>
<li>Check out the framework’s online API documentation. Which other datasets are available?</li>
</ol>
</section>
<section id="the-base-classification-model" class="slide level2">
<h2>The Base Classification Model</h2>
<p>:label:<code>sec_classification</code></p>
<ul>
<li><strong>Observation</strong>: Implementations from scratch and concise implementations using frameworks are similar for both regression and classification.</li>
<li><strong>Purpose</strong>: Since many models in this book deal with classification, we aim to add functionalities to support this setting specifically.</li>
<li><strong>Base Class</strong>: This section provides a base class for classification models to simplify future code.</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="im">from</span> d2l <span class="im">import</span> torch <span class="im">as</span> d2l</span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<h3 id="the-classifier-class">The <code>Classifier</code> Class</h3>
<ul>
<li><strong>Definition</strong>: <code>Classifier</code> class.</li>
<li><strong>Validation Step</strong>:
<ul>
<li>Reports both the loss value and classification accuracy on a validation batch.</li>
<li>Update every <code>num_val_batches</code> batches.</li>
<li>Generates averaged loss and accuracy on the whole validation data.</li>
<li>Average numbers may not be exact if the last batch contains fewer examples, but this is ignored for simplicity.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">class</span> Classifier(d2l.Module):  <span class="co">#@save</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>    <span class="co">"""The base class of classification models."""</span></span>
<span id="cb12-3"><a href="#cb12-3"></a>    <span class="kw">def</span> validation_step(<span class="va">self</span>, batch):</span>
<span id="cb12-4"><a href="#cb12-4"></a>        Y_hat <span class="op">=</span> <span class="va">self</span>(<span class="op">*</span>batch[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb12-5"><a href="#cb12-5"></a>        <span class="va">self</span>.plot(<span class="st">'loss'</span>, <span class="va">self</span>.loss(Y_hat, batch[<span class="op">-</span><span class="dv">1</span>]), train<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-6"><a href="#cb12-6"></a>        <span class="va">self</span>.plot(<span class="st">'acc'</span>, <span class="va">self</span>.accuracy(Y_hat, batch[<span class="op">-</span><span class="dv">1</span>]), train<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<p>By default we use a stochastic gradient descent optimizer, operating on minibatches, just as we did in the context of linear regression.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="at">@d2l.add_to_class</span>(d2l.Module)  <span class="co">#@save</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="kw">def</span> configure_optimizers(<span class="va">self</span>):</span>
<span id="cb13-3"><a href="#cb13-3"></a>    <span class="cf">return</span> torch.optim.SGD(<span class="va">self</span>.parameters(), lr<span class="op">=</span><span class="va">self</span>.lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<h3 id="accuracy">Accuracy</h3>
<ul>
<li><strong>Predicted Probability Distribution</strong>: <code>y_hat</code>
<ul>
<li>Choose the class with the highest predicted probability for hard predictions.</li>
<li>Example: Gmail categorizing emails into “Primary”, “Social”, “Updates”, “Forums”, or “Spam”.</li>
</ul></li>
<li><strong>Correct Predictions</strong>: When predictions match the label class <code>y</code>.
<ul>
<li><strong>Classification Accuracy</strong>: Fraction of correct predictions.</li>
<li>Difficult to optimize directly as it is not differentiable, but crucial for performance measurement and benchmarks.</li>
<li>Almost always reported when training classifiers.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Computing Accuracy</strong>:
<ul>
<li>Assume <code>y_hat</code> is a matrix with prediction scores for each class in the second dimension.</li>
<li>Use <code>argmax</code> to get the predicted class index for the largest entry in each row.</li>
<li>Compare predicted class with ground-truth <code>y</code> elementwise.</li>
<li>Convert <code>y_hat</code>’s data type to match <code>y</code> to ensure correct comparisons.</li>
<li>Result: Tensor with 0 (false) and 1 (true) entries.</li>
<li>Sum the tensor to get the number of correct predictions.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb14" data-n="9"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="at">@d2l.add_to_class</span>(Classifier)  <span class="co">#@save</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="kw">def</span> accuracy(<span class="va">self</span>, Y_hat, Y, averaged<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb14-3"><a href="#cb14-3"></a>    <span class="co">"""Compute the number of correct predictions."""</span></span>
<span id="cb14-4"><a href="#cb14-4"></a>    Y_hat <span class="op">=</span> d2l.reshape(Y_hat, (<span class="op">-</span><span class="dv">1</span>, Y_hat.shape[<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb14-5"><a href="#cb14-5"></a>    preds <span class="op">=</span> d2l.astype(d2l.argmax(Y_hat, axis<span class="op">=</span><span class="dv">1</span>), Y.dtype)</span>
<span id="cb14-6"><a href="#cb14-6"></a>    compare <span class="op">=</span> d2l.astype(preds <span class="op">==</span> d2l.reshape(Y, <span class="op">-</span><span class="dv">1</span>), d2l.float32)</span>
<span id="cb14-7"><a href="#cb14-7"></a>    <span class="cf">return</span> d2l.reduce_mean(compare) <span class="cf">if</span> averaged <span class="cf">else</span> compare</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="summary-1" class="slide level2">
<h2>Summary</h2>
<ul>
<li><strong>Common Problem</strong>: Classification is common enough to warrant its own convenience functions.</li>
<li><strong>Central Importance</strong>: <em>Accuracy</em> of the classifier.
<ul>
<li>Often the primary measure of performance.</li>
</ul></li>
<li><strong>Training Objectives</strong>:
<ul>
<li>Train classifiers to optimize various objectives for statistical and computational reasons.</li>
<li>Regardless of the loss function minimized during training, assessing accuracy empirically is crucial.</li>
</ul></li>
<li><strong>Convenience Method</strong>: Useful to have methods for assessing classifier accuracy.</li>
</ul>
</section>
<section id="exercises-2" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Denote by <span class="math inline">\(L_v\)</span> the validation loss, and let <span class="math inline">\(L_v^q\)</span> be its quick and dirty estimate computed by the loss function averaging in this section. Lastly, denote by <span class="math inline">\(l_v^b\)</span> the loss on the last minibatch. Express <span class="math inline">\(L_v\)</span> in terms of <span class="math inline">\(L_v^q\)</span>, <span class="math inline">\(l_v^b\)</span>, and the sample and minibatch sizes.</li>
<li>Show that the quick and dirty estimate <span class="math inline">\(L_v^q\)</span> is unbiased. That is, show that <span class="math inline">\(E[L_v] = E[L_v^q]\)</span>. Why would you still want to use <span class="math inline">\(L_v\)</span> instead?</li>
<li>Given a multiclass classification loss, denoting by <span class="math inline">\(l(y,y')\)</span> the penalty of estimating <span class="math inline">\(y'\)</span> when we see <span class="math inline">\(y\)</span> and given a probabilty <span class="math inline">\(p(y \mid x)\)</span>, formulate the rule for an optimal selection of <span class="math inline">\(y'\)</span>. Hint: express the expected loss, using <span class="math inline">\(l\)</span> and <span class="math inline">\(p(y \mid x)\)</span>.</li>
</ol>
</section>
<section id="softmax-regression-implementation-from-scratch" class="slide level2">
<h2>Softmax Regression Implementation from Scratch</h2>
<h3 id="implementing-softmax-regression">Implementing Softmax Regression</h3>
<ul>
<li><strong>Fundamental Concept</strong>: Softmax regression is a foundational model.</li>
<li><strong>Importance</strong>: Essential to understand and implement it yourself.</li>
<li><strong>Approach</strong>:
<ul>
<li>Define softmax-specific aspects of the model.</li>
<li>Reuse components from the linear regression section, including the training loop.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="im">from</span> d2l <span class="im">import</span> torch <span class="im">as</span> d2l</span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<h3 id="the-softmax-1">The Softmax</h3>
<ul>
<li><p><strong>Key Concept</strong>: Mapping from scalars to probabilities.</p></li>
<li><p><strong>Sum Operator</strong>: Recall the operation of the sum operator along specific dimensions in a tensor, as discussed in :numref:<code>subsec_lin-alg-reduction</code> and :numref:<code>subsec_lin-alg-non-reduction</code>.</p></li>
<li><p><strong>Example</strong>:</p>
<ul>
<li>Given a matrix <code>X</code>, sum over all elements by default or over elements in the same axis.</li>
<li>The <code>axis</code> variable allows for computing row and column sums.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>X <span class="op">=</span> d2l.tensor([[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>], [<span class="fl">4.0</span>, <span class="fl">5.0</span>, <span class="fl">6.0</span>]])</span>
<span id="cb16-2"><a href="#cb16-2"></a>d2l.reduce_sum(X, <span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>), d2l.reduce_sum(X, <span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<ul>
<li><strong>Computing the Softmax</strong>: Requires three steps:
<ol type="1">
<li>Exponentiation of each term.</li>
<li>Sum over each row to compute the normalization constant for each example.</li>
<li>Division of each row by its normalization constant, ensuring the result sums to 1.</li>
</ol></li>
</ul>
<p><span class="math display">\[
\mathrm{softmax}(\mathbf{X})_{ij} = \frac{\exp(\mathbf{X}_{ij})}{\sum_k \exp(\mathbf{X}_{ik})}.
\]</span></p>
</section>
<section class="slide level2">

<ul>
<li><strong>Partition Function</strong>:
<ul>
<li>The (logarithm of the) denominator is called the (log) <em>partition function</em>.</li>
<li>Introduced in <a href="https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics)">statistical physics</a> to sum over all possible states in a thermodynamic ensemble.</li>
</ul></li>
<li><strong>Implementation</strong>: The implementation is straightforward.</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="kw">def</span> softmax(X):</span>
<span id="cb17-2"><a href="#cb17-2"></a>    X_exp <span class="op">=</span> d2l.exp(X)</span>
<span id="cb17-3"><a href="#cb17-3"></a>    partition <span class="op">=</span> d2l.reduce_sum(X_exp, <span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-4"><a href="#cb17-4"></a>    <span class="cf">return</span> X_exp <span class="op">/</span> partition  <span class="co">## The broadcasting mechanism is applied here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<ul>
<li><p><strong>Input Transformation</strong>: For any input <code>X</code>, [<strong>each element is turned into a non-negative number, and each row sums up to 1</strong>], as required for a probability.</p></li>
<li><p><strong>Caution</strong>:</p>
<ul>
<li>The code above is <em>not</em> robust against very large or very small arguments.</li>
<li>While sufficient to illustrate the concept, do <em>not</em> use this code verbatim for serious purposes.</li>
</ul></li>
<li><p><strong>Best Practice</strong>:</p>
<ul>
<li>Deep learning frameworks have built-in protections.</li>
<li>Use the built-in softmax functions in deep learning frameworks going forward.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>X <span class="op">=</span> d2l.rand((<span class="dv">2</span>, <span class="dv">5</span>))</span>
<span id="cb18-2"><a href="#cb18-2"></a>X_prob <span class="op">=</span> softmax(X)</span>
<span id="cb18-3"><a href="#cb18-3"></a>X_prob, d2l.reduce_sum(X_prob, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<h3 id="the-model">The Model</h3>
<ul>
<li><p><strong>Softmax Regression Model</strong>: We now have everything needed to implement the softmax regression model.</p></li>
<li><p><strong>Instance Representation</strong>:</p>
<ul>
<li>Each instance represented by a fixed-length vector.</li>
<li>Raw data consists of <span class="math inline">\(28 \times 28\)</span> pixel images.</li>
<li>[<strong>Flatten each image, treating them as vectors of length 784.</strong>]</li>
</ul></li>
<li><p><strong>Future Improvements</strong>:</p>
<ul>
<li>Later chapters will introduce convolutional neural networks to exploit spatial structure more effectively.</li>
</ul></li>
<li><p><strong>Outputs</strong>:</p>
<ul>
<li>Number of outputs equals the number of classes.</li>
<li>(<strong>Dataset has 10 classes, so the network has an output dimension of 10.</strong>)</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Weights and Biases</strong>:
<ul>
<li>Weights: <span class="math inline">\(784 \times 10\)</span> matrix.</li>
<li>Biases: <span class="math inline">\(1 \times 10\)</span> dimensional row vector.</li>
<li>Initialize weights <code>W</code> with Gaussian noise.</li>
<li>Initialize biases as zeros.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="kw">class</span> SoftmaxRegressionScratch(d2l.Classifier):</span>
<span id="cb19-3"><a href="#cb19-3"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_inputs, num_outputs, lr, sigma<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb19-4"><a href="#cb19-4"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb19-5"><a href="#cb19-5"></a>        <span class="va">self</span>.save_hyperparameters()</span>
<span id="cb19-6"><a href="#cb19-6"></a>        <span class="va">self</span>.W <span class="op">=</span> torch.normal(<span class="dv">0</span>, sigma, size<span class="op">=</span>(num_inputs, num_outputs),</span>
<span id="cb19-7"><a href="#cb19-7"></a>                              requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-8"><a href="#cb19-8"></a>        <span class="va">self</span>.b <span class="op">=</span> torch.zeros(num_outputs, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-9"><a href="#cb19-9"></a></span>
<span id="cb19-10"><a href="#cb19-10"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb19-11"><a href="#cb19-11"></a>        <span class="cf">return</span> [<span class="va">self</span>.W, <span class="va">self</span>.b]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<h3 id="model-implementation">Model Implementation</h3>
<ul>
<li><strong>Mapping Input to Output</strong>:
<ul>
<li>The code below defines the network’s mapping from input to output.</li>
<li>Each <span class="math inline">\(28 \times 28\)</span> pixel image in the batch is flattened into a vector using <code>reshape</code> before passing through the model.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="kw">class</span> SoftmaxRegression(nn.Module):</span>
<span id="cb20-2"><a href="#cb20-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_inputs, num_outputs):</span>
<span id="cb20-3"><a href="#cb20-3"></a>        <span class="bu">super</span>(SoftmaxRegression, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb20-4"><a href="#cb20-4"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(num_inputs, num_outputs)</span>
<span id="cb20-5"><a href="#cb20-5"></a></span>
<span id="cb20-6"><a href="#cb20-6"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb20-7"><a href="#cb20-7"></a>        X <span class="op">=</span> X.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>))  <span class="co"># Flatten each image</span></span>
<span id="cb20-8"><a href="#cb20-8"></a>        <span class="cf">return</span> <span class="va">self</span>.linear(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="at">@d2l.add_to_class</span>(SoftmaxRegressionScratch)</span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb21-3"><a href="#cb21-3"></a>    X <span class="op">=</span> d2l.reshape(X, (<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.W.shape[<span class="dv">0</span>]))</span>
<span id="cb21-4"><a href="#cb21-4"></a>    <span class="cf">return</span> softmax(d2l.matmul(X, <span class="va">self</span>.W) <span class="op">+</span> <span class="va">self</span>.b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<h3 id="the-cross-entropy-loss">The Cross-Entropy Loss</h3>
<ul>
<li><strong>Common Loss Function</strong>:
<ul>
<li>The cross-entropy loss function is perhaps the most common in deep learning.</li>
<li>Widely used in classification problems, more so than regression problems.</li>
</ul></li>
<li><strong>Definition</strong>:
<ul>
<li>Cross-entropy takes the negative log-likelihood of the predicted probability assigned to the true label.</li>
<li>Avoid Python for-loops for efficiency; use indexing instead.</li>
<li>One-hot encoding in <span class="math inline">\(\mathbf{y}\)</span> allows selecting matching terms in <span class="math inline">\(\hat{\mathbf{y}}\)</span>.</li>
</ul></li>
<li><strong>Example</strong>:
<ul>
<li>Create sample data <code>y_hat</code> with 2 examples of predicted probabilities over 3 classes and their corresponding labels <code>y</code>.</li>
<li>Correct labels: <span class="math inline">\(0\)</span> and <span class="math inline">\(2\)</span> (i.e., the first and third class).</li>
<li>Use <code>y</code> as indices of probabilities in <code>y_hat</code> to pick out terms efficiently.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>y <span class="op">=</span> d2l.tensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb22-2"><a href="#cb22-2"></a>y_hat <span class="op">=</span> d2l.tensor([[<span class="fl">0.1</span>, <span class="fl">0.3</span>, <span class="fl">0.6</span>], [<span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.5</span>]])</span>
<span id="cb22-3"><a href="#cb22-3"></a>y_hat[[<span class="dv">0</span>, <span class="dv">1</span>], y]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now we can (<strong>implement the cross-entropy loss function</strong>) by averaging over the logarithms of the selected probabilities.</p>
</section>
<section class="slide level2">

<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="kw">def</span> cross_entropy(y_hat, y):</span>
<span id="cb23-2"><a href="#cb23-2"></a>    <span class="cf">return</span> <span class="op">-</span>d2l.reduce_mean(d2l.log(y_hat[<span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(y_hat))), y]))</span>
<span id="cb23-3"><a href="#cb23-3"></a></span>
<span id="cb23-4"><a href="#cb23-4"></a>cross_entropy(y_hat, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="at">@d2l.add_to_class</span>(SoftmaxRegressionScratch)</span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="kw">def</span> loss(<span class="va">self</span>, y_hat, y):</span>
<span id="cb24-3"><a href="#cb24-3"></a>    <span class="cf">return</span> cross_entropy(y_hat, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training" class="slide level2">
<h2>Training</h2>
<ul>
<li><strong>Reusing <code>fit</code> Method</strong>: Use the <code>fit</code> method defined in :numref:<code>sec_linear_scratch</code> to [<strong>train the model with 10 epochs.</strong>]</li>
<li><strong>Adjustable Hyperparameters</strong>:
<ul>
<li><strong>Number of epochs</strong> (<code>max_epochs</code>)</li>
<li><strong>Minibatch size</strong> (<code>batch_size</code>)</li>
<li><strong>Learning rate</strong> (<code>lr</code>)</li>
<li>These hyperparameters are not learned during the primary training loop but influence model performance.</li>
</ul></li>
<li><strong>Hyperparameter Tuning</strong>:
<ul>
<li>Choose values based on the <em>validation</em> split of the data.</li>
<li>Evaluate the final model on the <em>test</em> split.</li>
</ul></li>
<li><strong>Evaluation</strong>:
<ul>
<li>Treat the test data of Fashion-MNIST as the validation set.</li>
<li>Report validation loss and validation accuracy on this split.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<div class="sourceCode" id="cb25"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>data <span class="op">=</span> d2l.FashionMNIST(batch_size<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb25-2"><a href="#cb25-2"></a>model <span class="op">=</span> SoftmaxRegressionScratch(num_inputs<span class="op">=</span><span class="dv">784</span>, num_outputs<span class="op">=</span><span class="dv">10</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb25-3"><a href="#cb25-3"></a>trainer <span class="op">=</span> d2l.Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb25-4"><a href="#cb25-4"></a>trainer.fit(model, data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="prediction">Prediction</h3>
<p>Now that training is complete, our model is ready to [<strong>classify some images.</strong>]</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>X, y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(data.val_dataloader()))</span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="cf">if</span> tab.selected(<span class="st">'pytorch'</span>, <span class="st">'mxnet'</span>, <span class="st">'tensorflow'</span>):</span>
<span id="cb26-3"><a href="#cb26-3"></a>    preds <span class="op">=</span> d2l.argmax(model(X), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="cf">if</span> tab.selected(<span class="st">'jax'</span>):</span>
<span id="cb26-5"><a href="#cb26-5"></a>    preds <span class="op">=</span> d2l.argmax(model.<span class="bu">apply</span>({<span class="st">'params'</span>: trainer.state.params}, X), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-6"><a href="#cb26-6"></a>preds.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="error-analysis">Error Analysis</h3>
<ul>
<li><strong>Focus</strong>: More interested in images labeled <em>incorrectly</em>.</li>
<li><strong>Visualization</strong>:
<ul>
<li>Compare actual labels (first line of text output) with model predictions (second line of text output).</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode numberSource python input number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a>wrong <span class="op">=</span> d2l.astype(preds, y.dtype) <span class="op">!=</span> y</span>
<span id="cb27-2"><a href="#cb27-2"></a>X, y, preds <span class="op">=</span> X[wrong], y[wrong], preds[wrong]</span>
<span id="cb27-3"><a href="#cb27-3"></a>labels <span class="op">=</span> [a<span class="op">+</span><span class="st">'</span><span class="ch">\n</span><span class="st">'</span><span class="op">+</span>b <span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>(</span>
<span id="cb27-4"><a href="#cb27-4"></a>    data.text_labels(y), data.text_labels(preds))]</span>
<span id="cb27-5"><a href="#cb27-5"></a>data.visualize([X, y], labels<span class="op">=</span>labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="summary-2" class="slide level2">
<h2>Summary</h2>
<ul>
<li><strong>Experience Gained</strong>:
<ul>
<li>Solving linear regression and classification problems.</li>
<li>Reached the state of the art of 1960-1970s statistical modeling.</li>
</ul></li>
<li><strong>Next Steps</strong>:
<ul>
<li>Learn how to leverage deep learning frameworks.</li>
<li>Implement models more efficiently using these frameworks.</li>
</ul></li>
</ul>
</section>
<section id="exercises-3" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>In this section, we directly implemented the softmax function based on the mathematical definition of the softmax operation. As discussed in :numref:<code>sec_softmax</code> this can cause numerical instabilities.
<ol type="1">
<li>Test whether <code>softmax</code> still works correctly if an input has a value of <span class="math inline">\(100\)</span>?</li>
<li>Test whether <code>softmax</code> still works correctly if the largest of all inputs is smaller than <span class="math inline">\(-100\)</span>?</li>
<li>Implement a fix by looking at the value relative to the largest entry in the argument.</li>
</ol></li>
<li>Implement a <code>cross_entropy</code> function that follows the definition of the cross-entropy loss function <span class="math inline">\(\sum_i y_i \log \hat{y}_i\)</span>.
<ol type="1">
<li>Try it out in the code example above.</li>
<li>Why do you think it runs more slowly?</li>
<li>Should you use it? In which cases would it make sense?</li>
<li>What do you need to be careful of? Hint: consider the domain of the logarithm.</li>
</ol></li>
<li>Is it always a good idea to return the most likely label? For example, would you do this for medical diagnosis? How would you try to address this?</li>
<li>Assume that we want to use softmax regression to predict the next word based on some features. What are some problems that might arise from a large vocabulary?</li>
<li>Experiment with the hyperparameters of the code above. In particular:
<ol type="1">
<li>Plot how the validation loss changes as you change the learning rate.</li>
<li>Do the validation and training loss change as you change the minibatch size? How large or small do you need to go before you see an effect?</li>
</ol></li>
</ol>
</section>
<section id="generalization-and-overfitting" class="slide level2">
<h2>Generalization and Overfitting</h2>
<ul>
<li><strong>Focus</strong>: Tackling multiclass classification with linear neural networks, softmax functions, and cross-entropy loss.
<ul>
<li>Interpreted model outputs as probabilistic predictions.</li>
<li>Derived the cross-entropy loss function (negative log likelihood).</li>
<li>Fitted the model to the training set.</li>
</ul></li>
<li><strong>Goal</strong>: Learn <em>general patterns</em> assessed empirically on previously unseen data (the test set).
<ul>
<li>High accuracy on the training set is meaningless if it only reflects memorization.</li>
</ul></li>
<li><strong>Problem with Memorization</strong>:
<ul>
<li>Perfect accuracy on the training set can be achieved by memorizing the dataset.</li>
<li>Memorization doesn’t help classify new examples.</li>
<li>Without further guidance, new examples might require random guessing.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Key Questions</strong>:
<ol type="1">
<li>How many test examples are needed to precisely estimate the accuracy of classifiers on the underlying population?</li>
<li>What happens if we keep evaluating models on the same test set repeatedly?</li>
<li>Why should fitting our linear models to the training set fare better than naive memorization?</li>
</ol></li>
</ul>
</section>
<section id="overfitting-and-generalization" class="slide level2">
<h2>Overfitting and Generalization</h2>
<ul>
<li><strong>Previous Coverage</strong>:
<ul>
<li>Basics of overfitting and generalization discussed in :numref:<code>sec_generalization_basics</code> in the context of linear regression.</li>
</ul></li>
<li><strong>Current Chapter</strong>:
<ul>
<li>Delve deeper into foundational ideas of statistical learning theory.</li>
<li>Explore guarantees of generalization <em>a priori</em>.</li>
</ul></li>
<li><strong>Generalization Guarantees</strong>:
<ul>
<li>For many models, we can guarantee generalization within an upper bound <span class="math inline">\(\epsilon\)</span> on the generalization gap.</li>
<li>Determine the required number of samples <span class="math inline">\(n\)</span> to ensure the empirical error lies within <span class="math inline">\(\epsilon\)</span> of the true error, for any data generating distribution.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Practical Utility</strong>:
<ul>
<li>These guarantees are profound but limited in practical use for deep learning practitioners.</li>
<li>Ensuring generalization of deep neural networks <em>a priori</em> would require an absurd number of examples (potentially trillions).</li>
<li>In practice, deep neural networks generalize well with far fewer examples (thousands).</li>
</ul></li>
<li><strong>Practical Approach</strong>:
<ul>
<li>Forgo <em>a priori</em> guarantees.</li>
<li>Employ methods based on past performance on similar problems.</li>
<li>Certify generalization <em>post hoc</em> through empirical evaluations.</li>
</ul></li>
<li><strong>Future Discussion</strong>:
<ul>
<li>Revisit generalization in :numref:<code>chap_perceptrons</code>.</li>
<li>Provide an introduction to the scientific literature explaining why deep neural networks generalize in practice.</li>
</ul></li>
</ul>
</section>
<section id="the-test-set" class="slide level2">
<h2>The Test Set</h2>
<ul>
<li><strong>Role of Test Sets</strong>:
<ul>
<li>Used as the gold standard method for assessing generalization error.</li>
</ul></li>
<li><strong>Focus</strong>:
<ul>
<li>Discuss properties of generalization error estimates using a fixed classifier <span class="math inline">\(f\)</span>.</li>
<li>Assume a <em>fresh</em> dataset of examples <span class="math inline">\(\mathcal{D} = {(\mathbf{x}^{(i)},y^{(i)})}_{i=1}^n\)</span> not used to train the classifier.</li>
</ul></li>
<li><strong>Empirical Error</strong>:
<ul>
<li>Fraction of instances where the prediction <span class="math inline">\(f(\mathbf{x}^{(i)})\)</span> disagrees with the true label <span class="math inline">\(y^{(i)}\)</span>.</li>
<li>Given by:</li>
</ul></li>
</ul>
<p><span class="math display">\[\epsilon_\mathcal{D}(f) = \frac{1}{n}\sum_{i=1}^n \mathbf{1}(f(\mathbf{x}^{(i)}) \neq y^{(i)}).\]</span></p>
</section>
<section class="slide level2">

<ul>
<li><strong>Population Error</strong>:
<ul>
<li>Expected fraction of examples in the underlying population (distribution <span class="math inline">\(P(X,Y)\)</span>) where the classifier disagrees with the true label.</li>
<li>Given by:</li>
</ul></li>
</ul>
<p><span class="math display">\[\epsilon(f) =  E_{(\mathbf{x}, y) \sim P} \mathbf{1}(f(\mathbf{x}) \neq y) =
\int\int \mathbf{1}(f(\mathbf{x}) \neq y) p(\mathbf{x}, y) \;d\mathbf{x} dy.\]</span></p>
</section>
<section id="estimating-population-error" class="slide level2">
<h2>Estimating Population Error</h2>
<ul>
<li><strong>Population Error</strong>:
<ul>
<li><span class="math inline">\(\epsilon(f)\)</span> is the actual quantity of interest but cannot be directly observed.</li>
<li>Similar to estimating the average height in a large population without measuring every individual.</li>
</ul></li>
<li><strong>Empirical Error as Estimator</strong>:
<ul>
<li>Test set <span class="math inline">\(\mathcal{D}\)</span> is statistically representative of the population.</li>
<li><span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span> serves as a statistical estimator of <span class="math inline">\(\epsilon(f)\)</span>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Mean Estimation</strong>:
<ul>
<li>Estimating population error is a classic problem of mean estimation (see :numref:<code>sec_prob</code>).</li>
<li>Central limit theorem: With <span class="math inline">\(n\)</span> random samples drawn from any distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, the sample average <span class="math inline">\(\hat{\mu}\)</span> approximates a normal distribution centered at <span class="math inline">\(\mu\)</span> with standard deviation <span class="math inline">\(\sigma/\sqrt{n}\)</span>.</li>
</ul></li>
<li><strong>Convergence Rate</strong>:
<ul>
<li>As the number of examples grows, test error <span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span> approaches true error <span class="math inline">\(\epsilon(f)\)</span> at a rate of <span class="math inline">\(\mathcal{O}(1/\sqrt{n})\)</span>.</li>
<li>To estimate test error twice as precisely, collect four times as large a test set.</li>
<li>To reduce test error by a factor of one hundred, collect ten thousand times as large a test set.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Bernoulli Random Variable</strong>:
<ul>
<li>Random variable <span class="math inline">\(\mathbf{1}(f(X) \neq Y)\)</span> can take values 0 and 1 (Bernoulli random variable).</li>
<li>Parameter indicating probability of value 1 is the true error rate <span class="math inline">\(\epsilon(f)\)</span>.</li>
<li>Variance <span class="math inline">\(\sigma^2\)</span> of a Bernoulli distribution is <span class="math inline">\(\epsilon(f)(1-\epsilon(f))\)</span>.</li>
<li>Variance is highest when the true error rate is close to 0.5 and lower when close to 0 or 1.</li>
</ul></li>
<li><strong>Asymptotic Standard Deviation</strong>:
<ul>
<li>Asymptotic standard deviation of <span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span> over <span class="math inline">\(n\)</span> test samples cannot be greater than <span class="math inline">\(\sqrt{0.25/n}\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="estimating-population-error-continued" class="slide level2">
<h2>Estimating Population Error (Continued)</h2>
<ul>
<li><strong>Finite Sample Considerations</strong>:
<ul>
<li>Asymptotic rate characterizes behavior as test set size approaches infinity.</li>
<li>For <span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span> to approximate <span class="math inline">\(\epsilon(f)\)</span> within <span class="math inline">\(\pm 0.01\)</span> (one standard deviation), collect roughly 2500 samples.</li>
<li>For a 95% confidence interval (<span class="math inline">\(\epsilon_\mathcal{D}(f) \in \epsilon(f) \pm 0.01\)</span>), collect 10000 samples.</li>
</ul></li>
<li><strong>Popular Benchmarks</strong>:
<ul>
<li>Test set sizes for many popular benchmarks in machine learning are around 10000 samples.</li>
<li>Improvements of <span class="math inline">\(0.01\)</span> in error rates are significant, especially when error rates are close to <span class="math inline">\(0\)</span>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Finite Sample Bounds</strong>:
<ul>
<li>Asymptotic analysis provides general insights but for finite samples, use Hoeffding’s inequality:</li>
</ul></li>
</ul>
<p><span class="math display">\[P(\epsilon_\mathcal{D}(f) - \epsilon(f) \geq t) &lt; \exp\left( - 2n t^2 \right).\]</span></p>
<ul>
<li><strong>Example Calculation</strong>:
<ul>
<li>To conclude with 95% confidence that <span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span> is within <span class="math inline">\(0.01\)</span> of <span class="math inline">\(\epsilon(f)\)</span>, roughly 15000 examples are needed (compared to 10000 from asymptotic analysis).</li>
</ul></li>
<li><strong>General Trend</strong>:
<ul>
<li>Finite sample guarantees are more conservative but not drastically different from asymptotic estimates.</li>
<li>Asymptotic analysis remains useful for providing ballpark figures.</li>
</ul></li>
</ul>
</section>
<section id="test-set-reuse" class="slide level2">
<h2>Test Set Reuse</h2>
<ul>
<li><strong>Empirical ML Research</strong>:
<ul>
<li>Models developed and validated based on test set performance.</li>
<li>Evaluate test error <span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span> for any fixed classifier <span class="math inline">\(f\)</span> to understand population error <span class="math inline">\(\epsilon(f)\)</span>.</li>
</ul></li>
<li><strong>Training Initial Model</strong>:
<ul>
<li>Train model <span class="math inline">\(f_1\)</span> with an appropriate number of test examples.</li>
<li>Use a validation set for preliminary analysis, hyperparameter tuning, and model selection.</li>
<li>Evaluate <span class="math inline">\(f_1\)</span> on the test set, report unbiased population error estimate with confidence interval.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Developing New Models</strong>:
<ul>
<li>Develop a new model <span class="math inline">\(f_2\)</span> and tune it on the validation set.</li>
<li>Prepare to evaluate <span class="math inline">\(f_2\)</span> but realize the test set has already been used.</li>
</ul></li>
<li><strong>Issues with Test Set Reuse</strong>:
<ul>
<li>Original test set <span class="math inline">\(\mathcal{D}\)</span> was designed for a single classifier <span class="math inline">\(f\)</span>.</li>
<li>Evaluating multiple classifiers <span class="math inline">\(f_1, ..., f_k\)</span> on the same test set introduces the problem of false discovery.</li>
<li>With multiple classifiers, the probability of at least one misleading result increases.</li>
<li>Example: With 20 classifiers, ensuring no misleading score is challenging.</li>
</ul></li>
<li><strong>Multiple Hypothesis Testing</strong>:
<ul>
<li>Evaluating multiple hypotheses on the same dataset can lead to misleading conclusions.</li>
<li>Persistent problem in scientific research despite extensive statistical literature.</li>
</ul></li>
</ul>
</section>
<section id="concerns-with-test-set-reuse" class="slide level2">
<h2>Concerns with Test Set Reuse</h2>
<ul>
<li><strong>Distrusting Subsequent Evaluations</strong>:
<ul>
<li>Initial analysis assumes the classifier was chosen without contact with the test set.</li>
<li>Testing multiple functions and using the test set performance of <span class="math inline">\(f_1\)</span> to choose <span class="math inline">\(f_2\)</span> introduces bias.</li>
</ul></li>
<li><strong>Adaptive Overfitting</strong>:
<ul>
<li>Occurs when information from the test set leaks to the modeler.</li>
<li>Once leaked, the test set can no longer be a true test set.</li>
<li>Topic of interest in learning theory and statistics :cite:<code>dwork2015preserving</code>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Practical Guidance</strong>:
<ul>
<li>Create and use real test sets.</li>
<li>Consult test sets infrequently.</li>
<li>Account for multiple hypothesis testing when reporting confidence intervals.</li>
<li>Increase vigilance when stakes are high and dataset size is small.</li>
</ul></li>
<li><strong>Benchmark Challenges</strong>:
<ul>
<li>Maintain several test sets.</li>
<li>Demote old test sets to validation sets after each round.</li>
</ul></li>
</ul>
</section>
<section id="statistical-learning-theory" class="slide level2">
<h2>Statistical Learning Theory</h2>
<ul>
<li><strong>Importance of Test Sets</strong>:
<ul>
<li><em>Test sets are all that we really have</em> for evaluating generalization.</li>
<li>Seldom possess a true test set; often, someone else has already used it.</li>
<li>Even with a true test set, evaluating subsequent models can be frustrating and unreliable.</li>
</ul></li>
<li><strong>Limitations of Test Sets</strong>:
<ul>
<li>Only provide <em>post hoc</em> evidence of generalization.</li>
<li>Do not provide <em>a priori</em> reasons to expect generalization.</li>
</ul></li>
<li><strong>Appeal of Statistical Learning Theory</strong>:
<ul>
<li>Aims to elucidate principles explaining why/when models trained on empirical data generalize to unseen data.</li>
<li>Primary aim: bound the generalization gap, relating model properties to dataset size.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Empirical vs.&nbsp;True Error</strong>:
<ul>
<li>Learning theorists seek to bound the difference between the <em>empirical error</em> <span class="math inline">\(\epsilon_\mathcal{S}(f_\mathcal{S})\)</span> on training set <span class="math inline">\(\mathcal{S}\)</span> and the <em>true error</em> <span class="math inline">\(\epsilon(f_\mathcal{S})\)</span> on the population.</li>
<li>Different from evaluation of a fixed classifier on a separate test set.</li>
</ul></li>
<li><strong>Challenges with Classifier Collections</strong>:
<ul>
<li>Easy to estimate error for a single fixed classifier.</li>
<li>Difficult to estimate error accurately when considering collections of classifiers.</li>
<li>High probability of at least one classifier in the collection having a misleadingly low error.</li>
</ul></li>
<li><strong>Function Class Considerations</strong>:
<ul>
<li>When choosing a classifier from a set of functions <span class="math inline">\(\mathcal{F}\)</span>, there’s a risk of selecting one with a grossly underestimated population error.</li>
<li>Linear models with continuously valued parameters typically involve choosing from an infinite class of functions (<span class="math inline">\(|\mathcal{F}| = \infty\)</span>).</li>
</ul></li>
</ul>
</section>
<section id="statistical-learning-theory-continued" class="slide level2">
<h2>Statistical Learning Theory (Continued)</h2>
<ul>
<li><strong>Uniform Convergence</strong>:
<ul>
<li>Ambitious solution: develop tools for proving uniform convergence.</li>
<li>Goal: Empirical error rate for every classifier in the class <span class="math inline">\(\mathcal{F}\)</span> converges to its true error rate with high probability.</li>
<li>Theoretical principle: With probability at least <span class="math inline">\(1-\delta\)</span>, no classifier’s error rate <span class="math inline">\(\epsilon(f)\)</span> will be misestimated by more than some small amount <span class="math inline">\(\alpha\)</span>.</li>
</ul></li>
<li><strong>Model Class Flexibility</strong>:
<ul>
<li>Not all model classes <span class="math inline">\(\mathcal{F}\)</span> can achieve uniform convergence.</li>
<li>Example: Class of memorizers (always achieve empirical error <span class="math inline">\(0\)</span> but fail on the population).</li>
<li>Tradeoff: Flexible (high variance) models fit training data well but risk overfitting. Rigid (high bias) models generalize well but risk underfitting.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Central Question</strong>:
<ul>
<li>Quantify where a model sits on the bias-variance spectrum.</li>
<li>Provide guarantees on model performance.</li>
</ul></li>
<li><strong>Vapnik-Chervonenkis (VC) Dimension</strong>:
<ul>
<li>Series of seminal papers by Vapnik and Chervonenkis extended theory on convergence of relative frequencies.</li>
<li>VC dimension measures the complexity (flexibility) of a model class.</li>
<li>Key result: Bound on the difference between empirical error and population error as a function of VC dimension and number of samples:</li>
</ul></li>
</ul>
<p><span class="math display">\[
P\left(R[p, f] - R_\mathrm{emp}[\mathbf{X}, \mathbf{Y}, f] &lt; \alpha\right) \geq 1-\delta
\ \text{ for }\ \alpha \geq c \sqrt{(\mathrm{VC} - \log \delta)/n}.
\]</span></p>
</section>
<section id="statistical-learning-theory-continued-1" class="slide level2">
<h2>Statistical Learning Theory (Continued)</h2>
<ul>
<li><strong>Key Parameters</strong>:
<ul>
<li><span class="math inline">\(\delta &gt; 0\)</span>: Probability that the bound is violated.</li>
<li><span class="math inline">\(\alpha\)</span>: Upper bound on the generalization gap.</li>
<li><span class="math inline">\(n\)</span>: Dataset size.</li>
<li><span class="math inline">\(c &gt; 0\)</span>: Constant depending on the scale of the loss.</li>
</ul></li>
<li><strong>Using the Bound</strong>:
<ul>
<li>Plug in desired values of <span class="math inline">\(\delta\)</span> and <span class="math inline">\(\alpha\)</span> to determine the required number of samples.</li>
</ul></li>
<li><strong>VC Dimension</strong>:
<ul>
<li>Measures the largest number of data points for which any arbitrary (binary) labeling can be assigned and find a model <span class="math inline">\(f\)</span> in the class that agrees with that labeling.</li>
<li>Example: Linear models on <span class="math inline">\(d\)</span>-dimensional inputs have VC dimension <span class="math inline">\(d+1\)</span>.
<ul>
<li>A line can assign any possible labeling to three points in two dimensions, but not to four.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Practical Considerations</strong>:
<ul>
<li>The theory can be overly pessimistic for complex models.</li>
<li>Obtaining the guarantee typically requires more examples than actually needed to achieve the desired error rate.</li>
<li>Fixing the model class and <span class="math inline">\(\delta\)</span>, the error rate decays with the usual <span class="math inline">\(\mathcal{O}(1/\sqrt{n})\)</span> rate.</li>
</ul></li>
<li><strong>Generalization Gap</strong>:
<ul>
<li>While we may not do better in terms of <span class="math inline">\(n\)</span>, varying the model class can present a pessimistic picture of the generalization gap.</li>
</ul></li>
</ul>
</section>
<section id="summary-3" class="slide level2">
<h2>Summary</h2>
<ul>
<li><strong>Model Evaluation</strong>:
<ul>
<li>Use a test set of previously unseen data for evaluation.</li>
<li>Test set evaluations provide an unbiased estimate of true error.</li>
<li>Converge at the <span class="math inline">\(\mathcal{O}(1/\sqrt{n})\)</span> rate as the test set grows.</li>
<li>Provide approximate confidence intervals based on asymptotic distributions or conservative finite sample guarantees.</li>
</ul></li>
<li><strong>Challenges with Test Sets</strong>:
<ul>
<li>Often not true test sets (used repeatedly by multiple researchers).</li>
<li>Multiple evaluations on the same test set make controlling for false discovery difficult.</li>
<li>Significance of the problem depends on holdout set size and usage.</li>
<li>Good practice: curate real test sets (or multiple) and use them conservatively.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Statistical Learning Theory</strong>:
<ul>
<li>Developed methods for guaranteeing uniform convergence over a model class.</li>
<li>Uniform convergence ensures that every model’s empirical error converges to its true error simultaneously.</li>
<li>Allows for choosing the model that minimizes training error with confidence in its generalization.</li>
</ul></li>
<li><strong>VC Dimension</strong>:
<ul>
<li>Introduced by Vladimir Vapnik and Alexey Chervonenkis.</li>
<li>Measures the complexity of a model class.</li>
<li>Provides uniform convergence results for all models in a VC class.</li>
<li>Training errors for all models in the class grow closer to their true errors at <span class="math inline">\(\mathcal{O}(1/\sqrt{n})\)</span> rates.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Alternative Complexity Measures</strong>:
<ul>
<li>Numerous measures proposed for generalization guarantees (see :citet:<code>boucheron2005theory</code> for detailed discussion).</li>
<li>Useful in statistical theory but less effective for explaining deep neural networks’ generalization.</li>
</ul></li>
<li><strong>Deep Neural Networks</strong>:
<ul>
<li>Often have millions of parameters and can assign random labels to large datasets.</li>
<li>Generalize well on practical problems, often better when larger and deeper, despite larger VC dimensions.</li>
<li>Next chapter will revisit generalization in the context of deep learning.</li>
</ul></li>
</ul>
</section>
<section id="exercises-4" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>If we wish to estimate the error of a fixed model <span class="math inline">\(f\)</span> to within <span class="math inline">\(0.0001\)</span> with probability greater than 99.9%, how many samples do we need?</li>
<li>Suppose that somebody else possesses a labeled test set <span class="math inline">\(\mathcal{D}\)</span> and only makes available the unlabeled inputs (features). Now suppose that you can only access the test set labels by running a model <span class="math inline">\(f\)</span> (no restrictions placed on the model class) on each of the unlabeled inputs and receiving the corresponding error <span class="math inline">\(\epsilon_\mathcal{D}(f)\)</span>. How many models would you need to evaluate before you leak the entire test set and thus could appear to have error <span class="math inline">\(0\)</span>, regardless of your true error?</li>
<li>What is the VC dimension of the class of <span class="math inline">\(5^\mathrm{th}\)</span>-order polynomials?</li>
<li>What is the VC dimension of axis-aligned rectangles on two-dimensional data?</li>
</ol>
</section>
<section id="environment-and-distribution-shift" class="slide level2">
<h2>Environment and Distribution Shift</h2>
<p>:label:<code>sec_environment-and-distribution-shift</code></p>
<ul>
<li><strong>Context</strong>:
<ul>
<li>Previous sections focused on fitting models to datasets.</li>
<li>Did not consider where data originates or the ultimate use of model outputs.</li>
</ul></li>
<li><strong>Common Pitfall</strong>:
<ul>
<li>Rushing to develop models without considering data origins and usage.</li>
<li>Leads to failed deployments when data distribution shifts.</li>
</ul></li>
<li><strong>Distribution Shift Issues</strong>:
<ul>
<li>Models perform well on test sets but fail in deployment.</li>
<li>Deployment can perturb data distribution.</li>
<li>Example: Loan repayment model using footwear as a feature might cause behavior change without improving credit-worthiness.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Critical Considerations</strong>:
<ul>
<li>Decision-making based on model outputs can alter the environment.</li>
<li>Awareness of such impacts is crucial for responsible use of machine learning.</li>
</ul></li>
<li><strong>Mitigating Distribution Shift</strong>:
<ul>
<li>Expose common concerns and stimulate critical thinking.</li>
<li>Detect situations early and mitigate damage.</li>
<li>Use machine learning responsibly.</li>
</ul></li>
<li><strong>Solutions</strong>:
<ul>
<li>Simple: Ask for the “right” data.</li>
<li>Technically difficult: Implement reinforcement learning systems.</li>
<li>Ethical: Address philosophical questions about algorithm application.</li>
</ul></li>
</ul>
</section>
<section id="types-of-distribution-shift" class="slide level2">
<h2>Types of Distribution Shift</h2>
<ul>
<li><strong>Focus</strong>:
<ul>
<li>Passive prediction setting.</li>
<li>Ways data distributions might shift.</li>
<li>Salvaging model performance.</li>
</ul></li>
<li><strong>Classic Setup</strong>:
<ul>
<li>Training data sampled from distribution <span class="math inline">\(p_S(\mathbf{x}, y)\)</span>.</li>
<li>Test data drawn from a different distribution <span class="math inline">\(p_T(\mathbf{x}, y)\)</span>.</li>
<li>Learning a robust classifier is impossible without assumptions on how <span class="math inline">\(p_S\)</span> and <span class="math inline">\(p_T\)</span> relate.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Example</strong>:
<ul>
<li>Binary classification (dogs vs.&nbsp;cats).</li>
<li>If <span class="math inline">\(p_S(\mathbf{x}) = p_T(\mathbf{x})\)</span> but <span class="math inline">\(p_S(y \mid \mathbf{x}) = 1 - p_T(y \mid \mathbf{x})\)</span>, labels are flipped without changing the input distribution.</li>
<li>Impossible to distinguish from a setting where the distribution did not change.</li>
</ul></li>
<li><strong>Restricted Assumptions</strong>:
<ul>
<li>Under certain assumptions, algorithms can detect shifts.</li>
<li>Algorithms can sometimes adapt on the fly, improving classifier accuracy.</li>
</ul></li>
</ul>
</section>
<section id="covariate-shift" class="slide level2">
<h2>Covariate Shift</h2>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Covariate shift occurs when the distribution of inputs changes over time, but the labeling function (<span class="math inline">\(P(y \mid \mathbf{x})\)</span>) does not change.</li>
<li>The problem arises due to a shift in the distribution of the covariates (features).</li>
</ul></li>
<li><strong>Causality</strong>:
<ul>
<li>Covariate shift is a natural assumption when <span class="math inline">\(\mathbf{x}\)</span> causes <span class="math inline">\(y\)</span>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Example</strong>: Distinguishing cats and dogs.
<ul>
<li><strong>Training Data</strong>:
<ul>
<li>Consists of photos (see :numref:<code>fig_cat-dog-train</code>). <img data-src="../img/cat-dog-train.svg" alt="Training data for distinguishing cats and dogs."> :label:<code>fig_cat-dog-train</code></li>
</ul></li>
<li><strong>Test Data</strong>:
<ul>
<li>Consists of cartoons (see :numref:<code>fig_cat-dog-test</code>). <img data-src="../img/cat-dog-test.svg" alt="Test data for distinguishing cats and dogs."> :label:<code>fig_cat-dog-test</code></li>
</ul></li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>Training on a dataset with different characteristics from the test set can cause issues.</li>
<li>Requires a coherent plan to adapt to the new domain.</li>
</ul></li>
</ul>
</section>
<section id="label-shift" class="slide level2">
<h2>Label Shift</h2>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Label shift occurs when the label marginal <span class="math inline">\(P(y)\)</span> can change, but the class-conditional distribution <span class="math inline">\(P(\mathbf{x} \mid y)\)</span> remains fixed across domains.</li>
<li>Assumption to make when <span class="math inline">\(y\)</span> causes <span class="math inline">\(\mathbf{x}\)</span>.</li>
</ul></li>
<li><strong>Example</strong>:
<ul>
<li>Predicting diagnoses given symptoms.</li>
<li>Relative prevalence of diagnoses changes over time, but diseases cause symptoms.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Simultaneous Occurrence</strong>:
<ul>
<li>Label shift and covariate shift can hold simultaneously in degenerate cases.</li>
<li>When the label is deterministic, covariate shift assumption is satisfied even when <span class="math inline">\(y\)</span> causes <span class="math inline">\(\mathbf{x}\)</span>.</li>
</ul></li>
<li><strong>Methodological Advantage</strong>:
<ul>
<li>Methods based on label shift assumption often involve manipulating low-dimensional objects (labels).</li>
<li>This is advantageous in deep learning where inputs are high-dimensional.</li>
</ul></li>
</ul>
</section>
<section id="concept-shift" class="slide level2">
<h2>Concept Shift</h2>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Concept shift occurs when the definitions of labels change over time or across different contexts.</li>
<li>Example: Categories like diagnostic criteria for mental illness, fashion trends, and job titles.</li>
</ul></li>
<li><strong>Example</strong>:
<ul>
<li>Geographic variation in names for <em>soft drinks</em> in the United States (see :numref:<code>fig_popvssoda</code>).</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p><img data-src="../img/popvssoda.png" width="700" alt="Concept shift on soft drink names in the United States."> <code>fig_popvssoda</code></p>
<ul>
<li><strong>Challenges</strong>:
<ul>
<li><span class="math inline">\(P(y \mid \mathbf{x})\)</span> can vary depending on location (e.g., machine translation systems).</li>
<li>Concept shift can be subtle and hard to detect.</li>
<li>Shift often occurs gradually, either temporally or geographically.</li>
</ul></li>
</ul>
<h3 id="examples-of-distribution-shift">Examples of Distribution Shift</h3>
<p>Before delving into formalism and algorithms, let’s discuss some concrete situations where covariate or concept shift might not be obvious.</p>
</section>
<section id="nonstationary-distributions" class="slide level2">
<h2>Nonstationary Distributions</h2>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Distribution changes slowly over time (nonstationary).</li>
<li>Model is not updated frequently enough.</li>
</ul></li>
<li><strong>Examples</strong>:
<ul>
<li>Computational advertising model not updated with new devices (e.g., iPad launch).</li>
<li>Spam filter that fails to adapt to new spam tactics.</li>
<li>Product recommendation system recommending seasonal items out of season (e.g., Santa hats after Christmas).</li>
</ul></li>
</ul>
</section>
<section id="correction-of-distribution-shift" class="slide level2">
<h2>Correction of Distribution Shift</h2>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Training and test distributions <span class="math inline">\(P(\mathbf{x}, y)\)</span> often differ.</li>
<li>Sometimes models work despite distribution shifts; other times, principled strategies are needed.</li>
</ul></li>
</ul>
<h4 id="empirical-risk-and-risk">Empirical Risk and Risk</h4>
<p>:label:<code>subsec_empirical-risk-and-risk</code></p>
<ul>
<li><strong>Model Training</strong>:
<ul>
<li>Iterate over features and labels of training data <span class="math inline">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span>.</li>
<li>Update model parameters <span class="math inline">\(f\)</span> after every minibatch.</li>
</ul></li>
<li><strong>Empirical Risk Minimization</strong>:
<ul>
<li>Minimize the loss on the training data:</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p><span class="math display">\[\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i),\]</span> :eqlabel:<code>eq_empirical-risk-min</code></p>
<ul>
<li><span class="math inline">\(l\)</span>: Loss function measuring “how bad” the prediction <span class="math inline">\(f(\mathbf{x}_i)\)</span> is given the label <span class="math inline">\(y_i\)</span>.</li>
<li><em>Empirical risk</em>: Average loss over the training data to approximate the <em>risk</em>.</li>
<li><em>Risk</em>: Expectation of the loss over the entire population of data drawn from true distribution <span class="math inline">\(p(\mathbf{x}, y)\)</span>.</li>
</ul>
<p><span class="math display">\[E_{p(\mathbf{x}, y)} [l(f(\mathbf{x}), y)] = \int\int l(f(\mathbf{x}), y) p(\mathbf{x}, y) \;d\mathbf{x}dy.\]</span> :eqlabel:<code>eq_true-risk</code></p>
<ul>
<li><strong>Practical Strategy</strong>:
<ul>
<li>In practice, we cannot obtain the entire population of data.</li>
<li><em>Empirical risk minimization</em> is used to approximate minimizing the risk.</li>
</ul></li>
</ul>
</section>
<section id="covariate-shift-correction" class="slide level2">
<h2>Covariate Shift Correction</h2>
<ul>
<li><p><strong>Goal</strong>: Estimate <span class="math inline">\(P(y \mid \mathbf{x})\)</span> using labeled data <span class="math inline">\((\mathbf{x}_i, y_i)\)</span> drawn from a <em>source distribution</em> <span class="math inline">\(q(\mathbf{x})\)</span> instead of the <em>target distribution</em> <span class="math inline">\(p(\mathbf{x})\)</span>.</p></li>
<li><p><strong>Dependency Assumption</strong>: Conditional distribution does not change: <span class="math inline">\(p(y \mid \mathbf{x}) = q(y \mid \mathbf{x})\)</span>.</p></li>
<li><p><strong>Risk Correction</strong>:</p>
<ul>
<li>Use the identity to reweigh each data example:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}
\]</span></p>
</section>
<section class="slide level2">

<ul>
<li><strong>Weight Calculation</strong>:
<ul>
<li>Reweigh each example by the ratio <span class="math inline">\(\beta_i = \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}\)</span>.</li>
<li>Train the model using <em>weighted empirical risk minimization</em>:</li>
</ul></li>
</ul>
<p><span class="math display">\[\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n \beta_i l(f(\mathbf{x}_i), y_i).\]</span> <code>eq_weighted-empirical-risk-min</code></p>
</section>
<section class="slide level2">

<ul>
<li><strong>Estimating the Ratio</strong>:
<ul>
<li>Estimate the ratio <span class="math inline">\(\frac{p(\mathbf{x})}{q(\mathbf{x})}\)</span>.</li>
<li>Requires samples from both distributions: true <span class="math inline">\(p(\mathbf{x})\)</span> (e.g., test data) and training set <span class="math inline">\(q(\mathbf{x})\)</span>.</li>
<li>Only need features <span class="math inline">\(\mathbf{x} \sim p(\mathbf{x})\)</span>, not labels <span class="math inline">\(y \sim p(y)\)</span>.</li>
</ul></li>
<li><strong>Effective Approach</strong>: Logistic Regression
<ul>
<li>Learn a classifier to distinguish between data drawn from <span class="math inline">\(p(\mathbf{x})\)</span> and data drawn from <span class="math inline">\(q(\mathbf{x})\)</span>.</li>
<li>If instances are indistinguishable, they are equally likely from either distribution.</li>
<li>Well-discriminated instances should be significantly overweighted or underweighted accordingly.</li>
</ul></li>
</ul>
</section>
<section id="covariate-shift-correction-1" class="slide level2">
<h2>Covariate Shift Correction</h2>
<ul>
<li><strong>Assumption</strong>: Equal number of instances from distributions <span class="math inline">\(p(\mathbf{x})\)</span> and <span class="math inline">\(q(\mathbf{x})\)</span>.</li>
<li><strong>Labels</strong>:
<ul>
<li><span class="math inline">\(z = 1\)</span> for data from <span class="math inline">\(p\)</span>.</li>
<li><span class="math inline">\(z = -1\)</span> for data from <span class="math inline">\(q\)</span>.</li>
</ul></li>
<li><strong>Probability in Mixed Dataset</strong>:
<ul>
<li><span class="math display">\[P(z=1 \mid \mathbf{x}) = \frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})}\]</span></li>
<li><span class="math display">\[\frac{P(z=1 \mid \mathbf{x})}{P(z=-1 \mid \mathbf{x})} = \frac{p(\mathbf{x})}{q(\mathbf{x})}\]</span></li>
</ul></li>
<li><strong>Logistic Regression Approach</strong>:
<ul>
<li><span class="math display">\[P(z=1 \mid \mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))}\]</span></li>
<li>Weight Calculation: <span class="math display">\[\beta_i = \exp(h(\mathbf{x}_i))\]</span></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Steps to Correct Covariate Shift</strong>:
<ol type="1">
<li>Distinguish between data from both distributions.</li>
<li>Perform weighted empirical risk minimization using weights <span class="math inline">\(\beta_i\)</span>.</li>
</ol></li>
<li><strong>Correction Algorithm</strong>:
<ul>
<li><strong>Training Set</strong>: <span class="math inline">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span></li>
<li><strong>Unlabeled Test Set</strong>: <span class="math inline">\(\{\mathbf{u}_1, \ldots, \mathbf{u}_m\}\)</span></li>
<li><strong>Assumption</strong>:
<ul>
<li><span class="math inline">\(\mathbf{x}_i\)</span> for <span class="math inline">\(1 \leq i \leq n\)</span> drawn from source distribution.</li>
<li><span class="math inline">\(\mathbf{u}_i\)</span> for <span class="math inline">\(1 \leq i \leq m\)</span> drawn from target distribution.</li>
</ul></li>
<li><strong>Prototypical Algorithm</strong>:
<ol type="1">
<li><strong>Step 1</strong>: Use logistic regression to estimate the weights <span class="math inline">\(\beta_i\)</span>.</li>
<li><strong>Step 2</strong>: Apply weighted empirical risk minimization with the weights <span class="math inline">\(\beta_i\)</span>.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ol type="1">
<li>Generate a binary-classification training set: <span class="math inline">\(\{(\mathbf{x}_1, -1), \ldots, (\mathbf{x}_n, -1), (\mathbf{u}_1, 1), \ldots, (\mathbf{u}_m, 1)\}\)</span>.</li>
<li>Train a binary classifier using logistic regression to get function <span class="math inline">\(h\)</span>.</li>
<li>Weigh training data using <span class="math inline">\(\beta_i = \exp(h(\mathbf{x}_i))\)</span> or better <span class="math inline">\(\beta_i = \min(\exp(h(\mathbf{x}_i)), c)\)</span> for some constant <span class="math inline">\(c\)</span>.</li>
<li>Use weights <span class="math inline">\(\beta_i\)</span> for training on <span class="math inline">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span> in :eqref:<code>eq_weighted-empirical-risk-min</code>.</li>
</ol>
<p><strong>Crucial Assumption</strong>: - For this scheme to work, each data example in the target distribution must have a nonzero probability of occurring at training time. - If <span class="math inline">\(p(\mathbf{x}) &gt; 0\)</span> but <span class="math inline">\(q(\mathbf{x}) = 0\)</span>, the corresponding importance weight would be infinity.</p>
</section>
<section id="label-shift-correction" class="slide level2">
<h2>Label Shift Correction</h2>
<ul>
<li><strong>Assumption</strong>: Classification task with <span class="math inline">\(k\)</span> categories.
<ul>
<li><span class="math inline">\(q\)</span> and <span class="math inline">\(p\)</span> are the source (training) and target (test) distributions, respectively.</li>
<li>Label distribution shifts: <span class="math inline">\(q(y) \neq p(y)\)</span>.</li>
<li>Class-conditional distribution remains the same: <span class="math inline">\(q(\mathbf{x} \mid y) = p(\mathbf{x} \mid y)\)</span>.</li>
</ul></li>
<li><strong>Risk Correction</strong>:
<ul>
<li>Use the following identity:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy.
\end{aligned}
\]</span></p>
</section>
<section class="slide level2">

<ul>
<li><strong>Label Likelihood Ratios</strong>:
<ul>
<li>Importance weights: <span class="math inline">\(\beta_i = \frac{p(y_i)}{q(y_i)}\)</span>.</li>
</ul></li>
<li><strong>Estimation of Weights</strong>:
<ul>
<li>Use a good model on the source distribution to get consistent estimates of these weights.</li>
<li>Inputs are high-dimensional (e.g., images), labels are simpler (e.g., categories).</li>
</ul></li>
<li><strong>Confusion Matrix</strong>:
<ul>
<li>Compute confusion matrix <span class="math inline">\(\mathbf{C}\)</span> using the validation set.</li>
<li><span class="math inline">\(\mathbf{C}\)</span> is a <span class="math inline">\(k \times k\)</span> matrix: columns are true labels, rows are predicted categories.</li>
<li>Each cell <span class="math inline">\(c_{ij}\)</span> is the fraction of predictions where the true label was <span class="math inline">\(j\)</span> and predicted label was <span class="math inline">\(i\)</span>.</li>
</ul></li>
<li><strong>Estimating Target Label Distribution</strong>:
<ul>
<li>Average model predictions on test data to get mean model outputs <span class="math inline">\(\mu(\hat{\mathbf{y}})\)</span>.</li>
<li><span class="math inline">\(\mu(\hat{y}_i)\)</span>: fraction of predictions where the model predicted <span class="math inline">\(i\)</span>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Linear System</strong>:
<ul>
<li>Estimate test set label distribution by solving <span class="math inline">\(\mathbf{C} p(\mathbf{y}) = \mu(\hat{\mathbf{y}})\)</span>.</li>
<li>Solution: <span class="math inline">\(p(\mathbf{y}) = \mathbf{C}^{-1} \mu(\hat{\mathbf{y}})\)</span> if <span class="math inline">\(\mathbf{C}\)</span> is invertible.</li>
</ul></li>
<li><strong>Calculating Weights</strong>:
<ul>
<li>Estimate <span class="math inline">\(q(y)\)</span> from source data.</li>
<li>For any training example <span class="math inline">\(i\)</span> with label <span class="math inline">\(y_i\)</span>, calculate weight <span class="math inline">\(\beta_i = \frac{p(y_i)}{q(y_i)}\)</span>.</li>
<li>Use weights in weighted empirical risk minimization in :eqref:<code>eq_weighted-empirical-risk-min</code>.</li>
</ul></li>
</ul>
</section>
<section id="concept-shift-correction" class="slide level2">
<h2>Concept Shift Correction</h2>
<ul>
<li><strong>Challenge</strong>:
<ul>
<li>Concept shift is harder to correct in a principled manner.</li>
<li>Example: Shift from distinguishing cats vs.&nbsp;dogs to white vs.&nbsp;black animals may require new labels and training from scratch.</li>
<li>Extreme shifts are rare; usually, the task changes slowly over time.</li>
</ul></li>
<li><strong>Examples</strong>:
<ul>
<li><strong>Computational Advertising</strong>: New products are launched, old products become less popular. Distribution over ads and their popularity changes gradually.</li>
<li><strong>Traffic Cameras</strong>: Lenses degrade gradually due to environmental wear, affecting image quality progressively.</li>
<li><strong>News Content</strong>: Changes gradually with new stories appearing while most news remains unchanged.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Approach</strong>:
<ul>
<li>Use existing network weights and perform a few update steps with new data to adapt to gradual changes, rather than training from scratch.</li>
</ul></li>
</ul>
</section>
<section id="a-taxonomy-of-learning-problems" class="slide level2">
<h2>A Taxonomy of Learning Problems</h2>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Consider other aspects of machine learning problem formulation with knowledge on dealing with distribution changes.</li>
</ul></li>
</ul>
<h4 id="batch-learning">Batch Learning</h4>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Training a model <span class="math inline">\(f(\mathbf{x})\)</span> using a batch of training features and labels <span class="math inline">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span>.</li>
<li>Model is deployed to score new data <span class="math inline">\((\mathbf{x}, y)\)</span> drawn from the same distribution.</li>
</ul></li>
<li><strong>Example</strong>:
<ul>
<li>Train a cat detector with pictures of cats and dogs.</li>
<li>Deploy as part of a smart catdoor system, which is then installed and never updated again.</li>
</ul></li>
</ul>
<h4 id="online-learning">Online Learning</h4>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Data <span class="math inline">\((\mathbf{x}_i, y_i)\)</span> arrives one sample at a time.</li>
<li>Observe <span class="math inline">\(\mathbf{x}_i\)</span>, estimate <span class="math inline">\(f(\mathbf{x}_i)\)</span>, then observe <span class="math inline">\(y_i\)</span> and update the model based on the incurred loss.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Example</strong>:
<ul>
<li>Predict tomorrow’s stock price, trade based on the estimate, and learn from the profit or loss at the end of the day.</li>
</ul></li>
<li><strong>Cycle</strong>:</li>
</ul>
<p><span class="math display">\[
\mathrm{model} ~ f_t \longrightarrow
\mathrm{data} ~ \mathbf{x}_t \longrightarrow
\mathrm{estimate} ~ f_t(\mathbf{x}_t) \longrightarrow\\
\mathrm{observation} ~ y_t \longrightarrow
\mathrm{loss} ~ l(y_t, f_t(\mathbf{x}_t)) \longrightarrow
\mathrm{model} ~ f_{t+1}
\]</span></p>
</section>
<section class="slide level2">

<h4 id="control">Control</h4>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Environment remembers previous actions, influencing current observations.</li>
</ul></li>
<li><strong>Examples</strong>:
<ul>
<li><strong>PID Controller</strong>: Adjusts heating based on previous boiler temperatures.</li>
<li><strong>User Behavior</strong>: Depends on previously shown news articles.</li>
</ul></li>
<li><strong>Applications</strong>:
<ul>
<li>Model the environment to make decisions less random.</li>
<li>Used for automatic hyperparameter tuning to improve model performance :cite:<code>Shao.Yao.Sun.ea.2020</code>.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h4 id="considering-the-environment">Considering the Environment</h4>
<ul>
<li><strong>Key Distinction</strong>:
<ul>
<li>Strategies for stationary environments may not work when environments adapt.</li>
</ul></li>
<li><strong>Example</strong>:
<ul>
<li>Arbitrage opportunity disappears once exploited by a trader.</li>
</ul></li>
<li><strong>Algorithm Selection</strong>:
<ul>
<li>Environment changes determine suitable algorithms.</li>
<li>Slow changes: Force estimates to change slowly.</li>
<li>Instantaneous but infrequent changes: Make allowances for sudden shifts.</li>
</ul></li>
<li><strong>Crucial Knowledge</strong>:
<ul>
<li>Understanding environment dynamics is essential for dealing with concept shift.</li>
</ul></li>
</ul>
</section>
<section id="summary-4" class="slide level2">
<h2>Summary</h2>
<ul>
<li><strong>Distribution Shift</strong>:
<ul>
<li>Training and test sets may come from different distributions.</li>
<li>This mismatch is known as distribution shift.</li>
</ul></li>
<li><strong>Risk and Empirical Risk</strong>:
<ul>
<li>Risk: Expectation of the loss over the entire population drawn from the true distribution (usually unavailable).</li>
<li>Empirical Risk: Average loss over the training data, used to approximate risk.</li>
<li>Practical approach: Perform empirical risk minimization.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Covariate and Label Shift</strong>:
<ul>
<li>These types of shifts can be detected and corrected for at test time under corresponding assumptions.</li>
<li>Ignoring these biases can lead to problematic performance during testing.</li>
</ul></li>
<li><strong>Environment Response</strong>:
<ul>
<li>The environment may remember automated actions and respond in unexpected ways.</li>
<li>Important to consider this when building models.</li>
<li>Continuously monitor live systems to ensure models and environments do not become entangled in unanticipated ways.</li>
</ul></li>
</ul>

<img src="eclipse_logo_small.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p><a href="https://github.com/ECLIPSE-Lab/SS24_DataScienceForEM">SS24_DataScienceForEM</a></p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="05_CNN_class_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="05_CNN_class_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="05_CNN_class_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="05_CNN_class_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>